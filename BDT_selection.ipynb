{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to develop the BDT response & selection performance \n",
    "# work done by Kaushal Gumpula \n",
    "# see more at: https://github.com/kgumpula2/searchingfornues_BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "from selection_functions_kaushal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3?\n",
    "\n",
    "ISRUN3 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in offline flux reweight maps\n",
    "\n",
    "import ROOT\n",
    "\n",
    "if ISRUN3:\n",
    "    flux_maps = ROOT.TFile.Open(\"/uboone/data/users/kmiller/numi-ppfx/uboone/CV/no-threshold/feb2020/rhc/ppfx_weight_maps_rhc.root\")\n",
    "    plots_path = \"/uboone/data/users/kmiller/searchingfornues_v33/v08_00_00_33/plots/rhc/\"\n",
    "    \n",
    "else: \n",
    "    flux_maps = ROOT.TFile.Open(\"/uboone/data/users/kmiller/numi-ppfx/uboone/CV/no-threshold/feb2020/fhc/ppfx_weight_maps.root\")\n",
    "    plots_path = \"/uboone/app/users/kgumpula/work/searching_fornues_kaushal/plots/fhc/\"\n",
    "    \n",
    "numu_map = flux_maps.Get(\"hratio_numu\")\n",
    "numubar_map = flux_maps.Get(\"hratio_numubar\")\n",
    "nue_map = flux_maps.Get(\"hratio_nue\")\n",
    "nuebar_map = flux_maps.Get(\"hratio_nuebar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POT normalization factors\n",
    "\n",
    "if not ISRUN3: \n",
    "    overlay_pot = 2.31956E21        \n",
    "    dirt_pot = 1.42143E21\n",
    "    beamon_pot = 8.793E19 \n",
    "\n",
    "\n",
    "    beamon_ntrig = 2323130.0\n",
    "    beamoff_ntrig = 4015961.99 \n",
    "\n",
    "else: # RHC POT\n",
    "    overlay_pot = 1.57761E21\n",
    "    dirt_pot = 4.65831e+20\n",
    "    beamon_pot = 3.991E19\n",
    "    \n",
    "    beamon_ntrig = 815581.0\n",
    "    beamoff_ntrig = 1550231.025000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "\n",
    "EXT = \"\"\n",
    "OVRLY  = \"\"\n",
    "DRT = \"\"\n",
    "\n",
    "path = '/uboone/data/users/kmistry/work/MCC9/searchingfornues/'\n",
    "\n",
    "    \n",
    "if not ISRUN3: \n",
    "    # Run 1 FHC\n",
    "    OVRLY = 'ntuple_files_v5/neutrinoselection_filt_run1_overlay'\n",
    "    EXT = 'ntuple_files_v3/neutrinoselection_filt_run1_beamoff'\n",
    "    DRT = 'ntuple_files_v3/neutrinoselection_filt_run1_dirt_overlay'\n",
    "\n",
    "else: \n",
    "    # Run 3b RHC\n",
    "    OVRLY = 'ntuple_files_v5/neutrinoselection_filt_run3b_overlay'\n",
    "    EXT = 'ntuple_files_v2/neutrinoselection_filt_run3b_beamoff'\n",
    "    DRT = 'ntuple_files_v3/neutrinoselection_filt_run3b_dirt_overlay'\n",
    "\n",
    "overlay = uproot.open(path+OVRLY+\".root\")[fold][tree]\n",
    "ext = uproot.open(path+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(path+DRT+\".root\")[fold][tree]  \n",
    "    \n",
    "uproot_v = [overlay,ext,dirt]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"trk_score_v\", \n",
    "    \"category\", \"shr_tkfit_dedx_Y\", \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\",\n",
    "    \"shr_tkfit_nhits_Y\", \"shr_tkfit_nhits_U\", \"shr_tkfit_nhits_V\",\n",
    "    \"shr_hits_tot\", \"shr_hits_max\", \"ccnc\", \n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    \"crtveto\", \"crthitpe\", \"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"trkshrhitdist0\",\"trkshrhitdist1\",\"trkshrhitdist2\", # distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"nu_purity_from_pfp\", \n",
    "    \"shr_distance\", \"trk_distance\", \"isVtxInFiducial\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \n",
    "    \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \n",
    "    \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\", \"topological_score\",\n",
    "    \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"nslice\", \"interaction\",\n",
    "    \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\", \"contained_fraction\",\n",
    "    \"true_nu_vtx_x\", \"true_nu_vtx_y\" , \"true_nu_vtx_z\", \n",
    "    \"npion\", \"shr_energy_cali\", \"all_trk_energies\", \n",
    "    \"all_trk_hits\", \"all_shr_energies\", \"all_shr_hits\",\n",
    "    \"shrmoliereavg\", \"CosmicDirAll3D\", \"CosmicIPAll3D\",\n",
    "    \"elec_e\", \"proton_e\", \"nelec\", \"nmuon\", \"theta\",\n",
    "    \"elec_px\", \"elec_py\", \"elec_pz\",\"nu_pt\"\n",
    "]\n",
    "\n",
    "variables = variables\n",
    "\n",
    "if not ISRUN3: # i.e. if using Run1\n",
    "    variables.remove(\"_closestNuCosmicDist\")\n",
    "    variables.remove(\"crtveto\")\n",
    "    variables.remove(\"crthitpe\")\n",
    "    \n",
    "\n",
    "overlay = overlay.pandas.df(variables + [\"weightSplineTimesTune\", \"ppfx_cv\", \"swtrig_pre\"], flatten=False)\n",
    "dirt = dirt.pandas.df(variables + [\"weightSplineTimesTune\", \"ppfx_cv\", \"swtrig_pre\"], flatten=False)\n",
    "#data = data.pandas.df(variables, flatten=False)\n",
    "ext = ext.pandas.df(variables, flatten=False)\n",
    "\n",
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "#LLR-PID : log likelihood ratio particle ID ? \n",
    "\n",
    "df_v = [overlay,ext,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shr_tkfit_dedx_most\n",
    "\n",
    "for df in [overlay, dirt, ext]:\n",
    "    df['shr_tkfit_dedx_most'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[df['shr_tkfit_nhits_Y'] < df['shr_tkfit_nhits_V'], 'shr_tkfit_dedx_most'] = df['shr_tkfit_dedx_V']\n",
    "    df.loc[(df['shr_tkfit_nhits_V'] < df['shr_tkfit_nhits_U']) & (df['shr_tkfit_nhits_Y'] < df['shr_tkfit_nhits_U']), 'shr_tkfit_dedx_most'] = df['shr_tkfit_dedx_U']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts applied for bad GENIE weights \n",
    "\n",
    "for i,df in enumerate([overlay,dirt]):\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned POT normalization \n",
    "dirt_tune = 1\n",
    "ext_tune = 1\n",
    "if not ISRUN3: \n",
    "    dirt_tune = 0.35\n",
    "    ext_tune = .98\n",
    "else: \n",
    "    dirt_tune = 0.35\n",
    "    ext_tune = .94\n",
    "\n",
    "# POT normalization weights (scale to overlay)\n",
    "dirt_scale2 = dirt_tune*(overlay_pot/dirt_pot)\n",
    "beamoff_scale2 = ext_tune*((overlay_pot/beamon_pot)*(beamon_ntrig/beamoff_ntrig))\n",
    "\n",
    "dirt['pot_scale_overlay'] = dirt_scale2\n",
    "ext['pot_scale_overlay'] = beamoff_scale2\n",
    "overlay['pot_scale_overlay'] = [1 for i in range(len(overlay))]\n",
    "\n",
    "if not ISRUN3:\n",
    "    data_pot = 9.23E20\n",
    "else:\n",
    "    data_pot = 11.95E20\n",
    "    \n",
    "# POT normalization weights(scaled to data)\n",
    "dirt_scale3 = dirt_tune*(data_pot/dirt_pot)\n",
    "beamoff_scale3 = ext_tune*((data_pot/beamon_pot)*(beamon_ntrig/beamoff_ntrig))\n",
    "\n",
    "dirt['pot_scale_data'] = dirt_scale3\n",
    "ext['pot_scale_data'] = beamoff_scale3\n",
    "overlay['pot_scale_data'] = data_pot/overlay_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined flux * genie * POT weight \n",
    "# ext gets POT weight only \n",
    "\n",
    "# totweight scales to OVERLAY POT\n",
    "# flux weights will change values for RHC by at most 10%\n",
    "\n",
    "overlay['totweight_overlay'] = overlay['weightSplineTimesTune']*overlay['ppfx_cv']\n",
    "dirt['totweight_overlay'] = dirt['pot_scale_overlay']*dirt['weightSplineTimesTune']*dirt['ppfx_cv']\n",
    "\n",
    "# for data\n",
    "overlay['totweight_data'] = overlay['pot_scale_data']*overlay['weightSplineTimesTune']*overlay['ppfx_cv']\n",
    "dirt['totweight_data'] = dirt['pot_scale_data']*dirt['weightSplineTimesTune']*dirt['ppfx_cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out RHC runs from FHC dataset \n",
    "if not ISRUN3: \n",
    "    overlay = overlay.query('run<=10000')\n",
    "    dirt = dirt.query('run<=10000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selection_functions_BDT\n",
    "import importlib\n",
    "importlib.reload(selection_functions_BDT)\n",
    "from selection_functions_BDT import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_QUERY = 'nslice==1 and 10<=reco_nu_vtx_sce_x<=246 and -106<=reco_nu_vtx_sce_y<=106 and 10<=reco_nu_vtx_sce_z<=1026 and contained_fraction>0.9 and n_showers_contained>0 and n_tracks_contained>0'+' and shr_energy_tot_cali>0.07'+' and n_showers_contained==1'\n",
    "LOOSE_CUTS = 'shr_score<0.3 and trkpid<0.35 and shrmoliereavg<15 and shr_tkfit_dedx_Y<7 and tksh_distance<12'\n",
    "LOOSE_CUTS = PRE_QUERY+' and '+LOOSE_CUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISNUEBAR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISRUN3:\n",
    "    BOX_CUTS = 'nslice==1 and 10<=reco_nu_vtx_sce_x<=246 and -106<=reco_nu_vtx_sce_y<=106 and 10<=reco_nu_vtx_sce_z<=1026 and contained_fraction>0.9 and n_showers_contained==1 and n_tracks_contained>0 and shr_energy_tot_cali>0.07 and shrmoliereavg < 8.0 and tksh_distance < 4.0 and shr_tkfit_dedx_Y < 4.0 and -0.8<tksh_angle<0.8 and trkpid < 0 and shr_score < 0.125'\n",
    "else:\n",
    "    BOX_CUTS = 'nslice==1 and 10<=reco_nu_vtx_sce_x<=246 and -106<=reco_nu_vtx_sce_y<=106 and 10<=reco_nu_vtx_sce_z<=1026 and contained_fraction>0.9 and n_showers_contained==1 and n_tracks_contained>0 and shr_energy_tot_cali>0.07 and shrmoliereavg < 8.0 and tksh_distance < 5.0 and shr_tkfit_dedx_Y < 4.0 and -0.9<tksh_angle<0.8 and trkpid < 0 and shr_score < 0.125'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISDATA = True\n",
    "mc = pd.concat([overlay.query('swtrig_pre==1'),dirt.query('swtrig_pre==1')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-determined boosting round numbers\n",
    "\n",
    "if ISRUN3:\n",
    "    if ISNUEBAR:\n",
    "        p_rounds = 200\n",
    "        lc_rounds = 300\n",
    "    else:\n",
    "        p_rounds = 300\n",
    "        lc_rounds = 200\n",
    "else:\n",
    "    p_rounds = 300\n",
    "    lc_rounds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_p = main_BDT(mc, ext, PRE_QUERY, p_rounds, test_size=0.5, ISDATA=ISDATA, ISNUEBAR=ISNUEBAR)\n",
    "bdt_lc = main_BDT(mc, ext, LOOSE_CUTS, lc_rounds, test_size=0.5, ISDATA=ISDATA, ISNUEBAR=ISNUEBAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_test_results = bdt_lc[0]\n",
    "p_test_results = bdt_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_svb_plot(lc_test_results)\n",
    "bdt_svb_plot(p_test_results, is_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose cuts bdt results split into infv, outfv, cosmic, and ext events\n",
    "datasets_bdt = split_events(lc_test_results)\n",
    "\n",
    "plot_mc('BDT_score', 30, 0, 1, 'tuple()', datasets_bdt, 'dist', True, False, ISRUN3, 'totweight_overlay')\n",
    "plot_mc('BDT_score', 30, 0, 1, 'tuple()', datasets_bdt, 'dist', False, False, ISRUN3, 'totweight_overlay')\n",
    "plot_mc('nu_e', 20, 0, 5, 'BDT_score > 0.5', datasets_bdt, 'BDT', True, False, ISRUN3, 'totweight_overlay', ylim=60)\n",
    "plot_mc('nu_e', 20, 0, 5, 'BDT_score > 0.5', datasets_bdt, 'BDT', False, False, ISRUN3, 'totweight_overlay', ylim=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note test sample is equivalent regardless of query as query step happens after the initial split of testing and training data\n",
    "full_test_df = bdt_lc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bdt_lc[3]))\n",
    "print(len(bdt_lc[4]))\n",
    "print(len(bdt_lc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_pe_plot(lc_test_results, np.arange(0, 0.7, 0.025), full_test_df, ISDATA)\n",
    "bdt_pe_plot(p_test_results, np.arange(0, 0.7, 0.025), full_test_df, ISDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.arange(0, 0.7, 0.025)\n",
    "\n",
    "if ISDATA:\n",
    "    mc_weight = 'totweight_data'\n",
    "else:\n",
    "    mc_weight = 'totweight_overlay'\n",
    "\n",
    "gen_num = sum(full_test_df.query('is_signal==1 or is_cont_signal==1')[mc_weight])\n",
    "eff_box = sum(full_test_df.query(BOX_CUTS+' and is_signal==1')[mc_weight])/gen_num * 100\n",
    "pur_box = sum(full_test_df.query(BOX_CUTS+' and is_signal==1')[mc_weight]) / sum(full_test_df.query(BOX_CUTS)['weight']) * 100\n",
    "\n",
    "results_box = [pur_box, eff_box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_bdt_pe = bdt_pe(bdt_lc[0], xvals, full_test_df, ISDATA)\n",
    "p_bdt_pe = bdt_pe(bdt_p[0], xvals, full_test_df, ISDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_box_plot(lc_bdt_pe, results_box, xvals)\n",
    "bdt_box_plot(lc_bdt_pe, results_box, xvals, second_results_bdt=p_bdt_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISNUEBAR = False\n",
    "ISDATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISDATA:\n",
    "    mc_weight = 'totweight_data'\n",
    "else:\n",
    "    mc_weight = 'totweight_overlay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 2\n",
    "repeats = 20\n",
    "cv = RepeatedStratifiedKFold(n_splits=splits, n_repeats=repeats, random_state=36851234)\n",
    "\n",
    "bdt_score_arr = np.arange(0, 0.7, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.concat([mc, ext], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosmic cont. in FV signal definition for convenience in efficiency calculations later\n",
    "df_cv['is_cont_signal'] = np.where(((df_cv.nu_pdg == 12) & (df_cv.ccnc == 0) & (df_cv.nproton > 0) & (df_cv.npion == 0) & (df_cv.npi0 == 0)\n",
    "                               & (df_cv.nu_purity_from_pfp <= 0.5)\n",
    "                               & (10 <= df_cv.true_nu_vtx_x) & (df_cv.true_nu_vtx_x <= 246)\n",
    "                                & (-106 <= df_cv.true_nu_vtx_y) & (df_cv.true_nu_vtx_y <= 106)\n",
    "                               & (10 <= df_cv.true_nu_vtx_z) & (df_cv.true_nu_vtx_z <= 1026)), 1, 0)\n",
    "\n",
    "#true signal definition\n",
    "df_cv['is_signal'] = np.where(((df_cv.nu_pdg == 12) & (df_cv.ccnc == 0) & (df_cv.nproton > 0) & (df_cv.npion == 0) & (df_cv.npi0 == 0)\n",
    "                               & (df_cv.nu_purity_from_pfp > 0.5)\n",
    "                               & (10 <= df_cv.true_nu_vtx_x) & (df_cv.true_nu_vtx_x <= 246)\n",
    "                                & (-106 <= df_cv.true_nu_vtx_y) & (df_cv.true_nu_vtx_y <= 106)\n",
    "                               & (10 <= df_cv.true_nu_vtx_z) & (df_cv.true_nu_vtx_z <= 1026)), 1, 0)\n",
    "\n",
    "if ISNUEBAR:\n",
    "    #bdt signal definition (doesn't distinguish between nue and nuebar)\n",
    "    df_cv['is_nuebar_signal'] = np.where((((df_cv.nu_pdg == 12) | (df_cv.nu_pdg == -12)) & (df_cv.ccnc == 0) & (df_cv.nproton > 0) & (df_cv.npion == 0) & (df_cv.npi0 == 0)\n",
    "                                   & (df_cv.nu_purity_from_pfp > 0.5)\n",
    "                                   & (10 <= df_cv.true_nu_vtx_x) & (df_cv.true_nu_vtx_x <= 246)\n",
    "                                    & (-106 <= df_cv.true_nu_vtx_y) & (df_cv.true_nu_vtx_y <= 106)\n",
    "                                   & (10 <= df_cv.true_nu_vtx_z) & (df_cv.true_nu_vtx_z <= 1026)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist = [\n",
    "    \"shr_score\", \"shrmoliereavg\", \"trkpid\",\n",
    "    \"n_showers_contained\", \"shr_tkfit_dedx_Y\", \"tksh_distance\",\n",
    "    \"tksh_angle\", \"subcluster\", \"trkshrhitdist2\"]\n",
    "    \n",
    "#model params\n",
    "params = {\n",
    "    'eta': 0.02,\n",
    "    'tree_method': 'exact',\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1,\n",
    "    'silent': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'seed': 2002,\n",
    "    'gamma': 1,\n",
    "    'max_delta_step': 0,\n",
    "    #'scale_pos_weight': 4.7,\n",
    "    'eval_metric': ['error', 'auc', 'aucpr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_purity = []\n",
    "final_efficiency=[]\n",
    "fp_err = []\n",
    "fe_err = []\n",
    "fp_2=[]\n",
    "fe_2=[]\n",
    "fp_err2 = []\n",
    "fe_err2 = []\n",
    "\n",
    "box_pur = []\n",
    "box_eff = []\n",
    "boxp_err = []\n",
    "boxe_err = []\n",
    "\n",
    "for train_index, test_index in cv.split(df_cv, df_cv['is_signal']):\n",
    "    train, test = df_cv.iloc[train_index], df_cv.iloc[test_index]    \n",
    "    \n",
    "    if ISRUN3:\n",
    "        if ISNUEBAR:\n",
    "            p_rounds = 200\n",
    "            lc_rounds = 300\n",
    "        else:\n",
    "            p_rounds = 300\n",
    "            lc_rounds = 200\n",
    "    else:\n",
    "        p_rounds = 300\n",
    "        lc_rounds = 200\n",
    "        \n",
    "    bdt_cv_p = bdt_raw_results(train, test, PRE_QUERY, varlist, params, p_rounds, ISNUEBAR)\n",
    "    bdt_cv_lc = bdt_raw_results(train, test, LOOSE_CUTS, varlist, params, lc_rounds, ISNUEBAR)\n",
    "    \n",
    "    # saves purity, efficiency and respective errors on current test sample for loose cuts BDT\n",
    "    pur, pur_err, eff, eff_err = bdt_pe(bdt_cv_lc[0], bdt_score_arr, test, ISDATA)\n",
    "    final_purity.append(pur)\n",
    "    final_efficiency.append(eff)\n",
    "    fp_err2.append(pur_err)\n",
    "    fe_err2.append(eff_err)\n",
    "    \n",
    "    # saves purity, efficiency and respective errors on current test sample for preselection BDT\n",
    "    pur2, pur_err2, eff2, eff_err2 = bdt_pe(bdt_cv_p[0], bdt_score_arr, test, ISDATA)\n",
    "    fp_2.append(pur2)\n",
    "    fe_2.append(eff2)\n",
    "    fp_err2.append(pur_err2)\n",
    "    fe_err2.append(eff_err2)\n",
    "    \n",
    "    # saves purity and efficiency and respective errors for lienar box cut selection performance on current test sample\n",
    "    sig_sel = sum(test.query(BOX_CUTS+' and is_signal==1')[mc_weight])\n",
    "    tot_sel = sum(test.query(BOX_CUTS)['weight'])\n",
    "    tot_sig = sum(test.query('is_signal==1 or is_cont_signal==1')[mc_weight])\n",
    "    p = sig_sel / tot_sel\n",
    "    e = sig_sel / tot_sig\n",
    "    box_pur.append(p * 100)\n",
    "    box_eff.append(e * 100)\n",
    "    boxp_err.append(math.sqrt(sig_sel) / tot_sel * 100)\n",
    "    boxe_err.append(math.sqrt((e * (1-e)) / tot_sig) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages results column-wise which is equivalent to averaging results over the same BDT_score cut\n",
    "results_bdt = [np.mean(final_purity, axis=0), np.full(28, 0), np.mean(final_efficiency, axis=0), np.full(28, 0)]\n",
    "second_results_bdt = [np.mean(fp_2, axis=0), np.full(28, 0), np.mean(fe_2, axis=0), np.full(28, 0)]\n",
    "\n",
    "# linear box cut selection is a normal average over each distinct test sample\n",
    "results_box = [np.mean(box_pur), np.mean(box_eff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_box_plot(results_bdt, results_box, bdt_score_arr, second_results_bdt=second_results_bdt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
