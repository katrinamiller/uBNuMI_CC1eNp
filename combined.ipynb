{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'backend_functions')\n",
    "\n",
    "import selection_functions as sf\n",
    "\n",
    "import importlib\n",
    "\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT\n",
    "\n",
    "import top \n",
    "from top import *\n",
    "\n",
    "import uncertainty_functions \n",
    "from uncertainty_functions import *\n",
    "\n",
    "import xsec_functions \n",
    "from xsec_functions import smear_matrix\n",
    "\n",
    "from ROOT import TH1D, TH2D, TDirectory, TH1F, TH2F\n",
    "\n",
    "from selection_functions import *\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = 'shr_energy_cali'\n",
    "true_var = 'elec_e'\n",
    "bins = [0.02, 0.22, 0.42, 0.62, 0.82 , 1.22,  7]\n",
    "\n",
    "xlow = bins[0]\n",
    "xhigh = 2.5\n",
    "\n",
    "x_label = \"Shower Energy [GeV]\"\n",
    "\n",
    "x_ticks = [0.02, 0.22, 0.42, 0.62, 0.82 , 1.22, 2.5]\n",
    "\n",
    "bincenters = 0.5*(np.array(x_ticks)[1:]+np.array(x_ticks)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variations/FHCVariations_July15.json') as f_fhc:\n",
    "    fhc_dict = json.load(f_fhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variations/RHCVariations_July15.json') as f_rhc:\n",
    "    rhc_dict = json.load(f_rhc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v in fhc_dict['ppfx']: \n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=fhc_dict['evt_rate'],\n",
    "        histtype='step', color='black', linewidth=2)    \n",
    "\n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"PPFX VARIATIONS (FHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v in rhc_dict['ppfx']: \n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=rhc_dict['evt_rate'],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"PPFX VARIATIONS (RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppfx_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['ppfx'], rhc_dict['ppfx']): \n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc,v_rhc)]\n",
    "    ppfx_variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"PPFX VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(uncertainty_functions)\n",
    "from uncertainty_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_ppfx_dict = calcCov(xvar, bins, fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                    fhc_dict['ppfx'], plot=True, \n",
    "                    title='Hadronic Models', save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhc_ppfx_dict = calcCov(xvar, bins, rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                    rhc_dict['ppfx'], plot=True, \n",
    "                    title='Hadronic Models', save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate covariance \n",
    "\n",
    "ppfx_dict = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    ppfx_variations, plot=True, \n",
    "                    title='Hadronic Models', save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=ppfx_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_ppfx_dict['fractional_uncertainty'], linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_ppfx_dict['fractional_uncertainty'], linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.25)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"PPFX Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamline Geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamline_runs = ['HornCurrent', 'xHorn1', 'yHorn1', 'BeamSpotSize', 'xHorn2', 'yHorn2', 'WaterOnHorns', \n",
    "                'xBeamShift', 'yBeamShift', 'zTargetPosition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fhc_dict['beamline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_beamline_unisim_cov = {}\n",
    "rhc_beamline_unisim_cov = {}\n",
    "beamline_unisim_cov = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['beamline'], rhc_dict['beamline']): \n",
    "    \n",
    "    print(beamline_runs[i])\n",
    "    \n",
    "    variations = []\n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc[0],v_rhc[0])]\n",
    "    comb_v2 = [a+b for a,b in zip(v_fhc[1],v_rhc[1])]\n",
    "    \n",
    "    variations.append(comb_v)\n",
    "    variations.append(comb_v2)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 5)) \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v2,\n",
    "            histtype='step', color='cornflowerblue', linewidth=1)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "             weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "        histtype='step', color='black', linewidth=2)\n",
    "              \n",
    "    plt.xlim(xlow, 2.5)\n",
    "    plt.title(beamline_runs[i]+\" Variations (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "    plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "\n",
    "    plt.xlabel(x_label, fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    # compute unisim covariance\n",
    "    \n",
    "    fhc_beamline_unisim_cov[beamline_runs[i]] = calcCov(xvar, bins, \n",
    "                                                    fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                                                    v_fhc, plot=False, save=False)\n",
    "    \n",
    "    rhc_beamline_unisim_cov[beamline_runs[i]] = calcCov(xvar, bins, \n",
    "                                                    rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                                                    v_rhc, plot=False, save=False)\n",
    "    \n",
    "    beamline_unisim_cov[beamline_runs[i]] = calcCov(xvar, bins, \n",
    "                                                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                                                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                                                    variations, plot=False, save=False)\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,d in enumerate([fhc_beamline_unisim_cov, rhc_beamline_unisim_cov, beamline_unisim_cov]): \n",
    "    \n",
    "    cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    frac_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    cor = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    \n",
    "    for variation in d.keys(): \n",
    "\n",
    "        for i in range(len(bins)-1): \n",
    "            for j in range(len(bins)-1):\n",
    "\n",
    "                cov[i][j] += d[variation]['cov'][i][j]\n",
    "                frac_cov[i][j] += d[variation]['frac_cov'][i][j] \n",
    "\n",
    "\n",
    "    for i in range(len(bins)-1): \n",
    "        for j in range(len(bins)-1):\n",
    "\n",
    "            if np.sqrt(cov[i][i])*np.sqrt(cov[j][j]) != 0: \n",
    "                    cor[i][j] = cov[i][j] / (np.sqrt(cov[i][i])*np.sqrt(cov[j][j]))\n",
    "        \n",
    "    if k==0 or k==1: \n",
    "        print(np.sqrt(np.diag(frac_cov)))\n",
    "        \n",
    "    else: \n",
    "        beamline_unisim_dict = {\n",
    "            'cov' : cov, \n",
    "            'frac_cov' : frac_cov,\n",
    "            'cor' : cor,\n",
    "            'fractional_uncertainty' : np.sqrt(np.diag(frac_cov))\n",
    "        } \n",
    "\n",
    "        print(beamline_unisim_dict['fractional_uncertainty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=beamline_unisim_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=[0.03565191, 0.02926658, 0.03848975, 0.04442238, 0.07051269, 0.06698694], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=[0.03627028, 0.02598845, 0.03868571, 0.04285482, 0.04718215, 0.09892696], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.15)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"Beamline Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['genie_ms'], rhc_dict['genie_ms']): \n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc,v_rhc)]\n",
    "    genie_variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"GENIE VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_genie_dict = calcCov(xvar, bins, fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                    fhc_dict['genie_ms'], plot=False) \n",
    "\n",
    "rhc_genie_dict = calcCov(xvar, bins, rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                    rhc_dict['genie_ms'], plot=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_dict = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    genie_variations, plot=False, save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=genie_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_genie_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_genie_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "#plt.ylim(0, 0.15)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"GENIE (ms) Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_unisims = ['RPA', 'RPA', 'CCMEC', 'AxFFCCQE', 'VecFFCCQE', 'DecayAngMEC', 'ThetaDelta2Npi', 'ThetaDelta2NRad', \n",
    "                          'NormCCCOH', 'NormNCCOH', \n",
    "                          'xsr_scc_Fv3', 'xsr_scc_Fa3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_unisim_cov = {}\n",
    "fhc_genie_unisim_cov = {}\n",
    "rhc_genie_unisim_cov = {}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['genie_us'], rhc_dict['genie_us']): \n",
    "    \n",
    "    print(genie_unisims[i])\n",
    "    \n",
    "    variations = []\n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc[0],v_rhc[0])]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 5)) \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "    \n",
    "    if i==1:\n",
    "        comb_v2 = [a+b for a,b in zip(v_fhc[1],v_rhc[1])]\n",
    "        #genie_us_variations.append([comb_v, comb_v2])\n",
    "        variations.append(comb_v)\n",
    "        variations.append(comb_v2)\n",
    "    \n",
    "        plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v2,\n",
    "            histtype='step', color='cornflowerblue', linewidth=1)\n",
    "        \n",
    "    else: \n",
    "        variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "             weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "        histtype='step', color='black', linewidth=2)\n",
    "              \n",
    "    plt.xlim(xlow, 2.5)\n",
    "    plt.title(genie_unisims[i]+\" Variations (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "    plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "\n",
    "    plt.xlabel(x_label, fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    fhc_genie_unisim_cov[genie_unisims[i]] = calcCov(xvar, bins, \n",
    "                                                    fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                                                    v_fhc, plot=False, save=False)\n",
    "    \n",
    "    rhc_genie_unisim_cov[genie_unisims[i]] = calcCov(xvar, bins, \n",
    "                                                    rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                                                    v_rhc, plot=False, save=False)\n",
    "    \n",
    "    \n",
    "    # compute unisim covariance\n",
    "    genie_unisim_cov[genie_unisims[i]] = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                                     [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                                     variations, plot=False, save=False)\n",
    "    \n",
    "\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,d in enumerate([fhc_genie_unisim_cov, rhc_genie_unisim_cov, genie_unisim_cov]): \n",
    "    \n",
    "    cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    frac_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    cor = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "    \n",
    "    for variation in d.keys(): \n",
    "\n",
    "        for i in range(len(bins)-1): \n",
    "            for j in range(len(bins)-1):\n",
    "\n",
    "                cov[i][j] += d[variation]['cov'][i][j]\n",
    "                frac_cov[i][j] += d[variation]['frac_cov'][i][j] \n",
    "\n",
    "\n",
    "    for i in range(len(bins)-1): \n",
    "        for j in range(len(bins)-1):\n",
    "\n",
    "            if np.sqrt(cov[i][i])*np.sqrt(cov[j][j]) != 0: \n",
    "                    cor[i][j] = cov[i][j] / (np.sqrt(cov[i][i])*np.sqrt(cov[j][j]))\n",
    "        \n",
    "    if k==0 or k==1: \n",
    "        print(list(np.sqrt(np.diag(frac_cov))))\n",
    "        \n",
    "    else: \n",
    "        genie_unisim_dict = {\n",
    "            'cov' : cov, \n",
    "            'frac_cov' : frac_cov,\n",
    "            'cor' : cor,\n",
    "            'fractional_uncertainty' : np.sqrt(np.diag(frac_cov))\n",
    "        } \n",
    "\n",
    "        print(genie_unisim_dict['fractional_uncertainty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=genie_unisim_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=[0.07772277893028244, 0.023843003995427086, 0.02604231665943866, 0.021890860319963044, 0.03644975889572493, 0.03798103703037698], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=[0.06853959481825295, 0.027662974240252797, 0.08520362055369854, 0.057560672201180545, 0.03285804162032622, 0.029561164059373767], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.1)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"GENIE (us) Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEANT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geant4_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['geant4'], rhc_dict['geant4']): \n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc,v_rhc)]\n",
    "    geant4_variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"GEANT4 VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_geant4_dict = calcCov(xvar, bins, fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                    fhc_dict['geant4'], plot=False) \n",
    "\n",
    "rhc_geant4_dict = calcCov(xvar, bins, rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                    rhc_dict['geant4'], plot=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geant4_dict = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    geant4_variations, plot=False, save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=geant4_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_geant4_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_geant4_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.05)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"GEANT4 Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector systematics -- Using Reco X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variations/FHCDetSysVariations_July8.json') as f_fhc_detsys:\n",
    "    fhc_detsys_dict = json.load(f_fhc_detsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_detsys_dict['LYAttenuation_intrinsic'] = [0 for i in range(len(fhc_detsys_dict['CV_intrinsic'] ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variations/RHCDetSysVariations_July8.json') as f_rhc_detsys:\n",
    "    rhc_detsys_dict = json.load(f_rhc_detsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar_detsys = \"reco_nu_vtx_sce_x\"\n",
    "bins_detsys = [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bincenters_detsys = 0.5*(np.array(bins_detsys)[1:]+np.array(bins_detsys)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_err_detsys = [ round(abs(bins_detsys[x+1]-bins_detsys[x])/2, 3) for x in range(len(bins_detsys)-1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variation in rhc_detsys_dict.keys(): \n",
    "    \n",
    "    if variation=='CV_intrinsic': \n",
    "        continue\n",
    "        \n",
    "    plt.hist(bincenters_detsys, bins_detsys, histtype='step', range=[bins_detsys[0], bins_detsys[-1]], \n",
    "                 weights=[a+b for a,b in zip(fhc_detsys_dict[variation], rhc_detsys_dict[variation])], \n",
    "                            color='cornflowerblue', linewidth=0.5, label='UV')\n",
    "    \n",
    "        \n",
    "    if variation=='LYAttenuation_intrinsic': \n",
    "\n",
    "        plt.errorbar(bincenters_detsys, \n",
    "                     rhc_detsys_dict['CV_intrinsic'], \n",
    "                     xerr=x_err_detsys, \n",
    "                     fmt='none', color='black', linewidth=2, label='CV (RHC only)')\n",
    "        \n",
    "    else: \n",
    "\n",
    "        plt.errorbar(bincenters_detsys, \n",
    "                     [a+b for a,b in zip(fhc_detsys_dict['CV_intrinsic'], rhc_detsys_dict['CV_intrinsic'])], \n",
    "                     xerr=x_err_detsys, \n",
    "                     fmt='none', color='black', linewidth=2, label='CV')\n",
    "    \n",
    "    plt.xlabel(xvar, fontsize=14)\n",
    "    plt.title(variation+' (nue CC events)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detsys_cov_nueCC = {}\n",
    "\n",
    "for variation in fhc_detsys_dict.keys(): \n",
    "    \n",
    "    if variation=='CV': \n",
    "        continue\n",
    "        \n",
    "    if variation=='LYAttenuation_intrinsic': \n",
    "        \n",
    "        detsys_cov_nueCC[variation] = calcCov(xvar, bins_detsys, \n",
    "                                          rhc_detsys_dict['CV_intrinsic'], \n",
    "                                              rhc_detsys_dict['CV_intrinsic'], \n",
    "                                              [rhc_detsys_dict[variation]])\n",
    "        \n",
    "    else: \n",
    "   \n",
    "        detsys_cov_nueCC[variation] = calcCov(xvar_detsys, bins_detsys, \n",
    "                                          [a+b for a,b in zip(fhc_detsys_dict['CV_intrinsic'], rhc_detsys_dict['CV_intrinsic'])], \n",
    "                                              [a+b for a,b in zip(fhc_detsys_dict['CV_intrinsic'], rhc_detsys_dict['CV_intrinsic'])], \n",
    "                                              [[a+b for a,b in zip(fhc_detsys_dict[variation], rhc_detsys_dict[variation])]])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = [ [0]*(len(bins_detsys)-1) for x in range(len(bins_detsys)-1) ]\n",
    "frac_cov = [ [0]*(len(bins_detsys)-1) for x in range(len(bins_detsys)-1) ]\n",
    "\n",
    "for i in range(len(bins_detsys)-1): \n",
    "    for j in range(len(bins_detsys)-1):\n",
    "            \n",
    "        cov[i][j] = sum([detsys_cov_nueCC[x]['cov'][i][j] for x in rhc_detsys_dict.keys() if x is not 'CV_intrinsic'])\n",
    "        frac_cov[i][j] = sum([detsys_cov_nueCC[x]['frac_cov'][i][j] for x in rhc_detsys_dict.keys() if x is not 'CV_intrinsic'])\n",
    "\n",
    "nueCC_detsys_dict = {\n",
    "    'cov' : cov, \n",
    "    'frac_cov' : frac_cov,\n",
    "    'fractional_uncertainty' : np.sqrt(np.diag(frac_cov))\n",
    "} \n",
    "\n",
    "nueCC_detsys_dict['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_err = [ round(abs(bins[x+1]-bins[x])/2, 3) for x in range(len(bins)-1) ]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "cv_bdtcut = [a+b for a,b in zip(fhc_detsys_dict['CV_intrinsic'], rhc_detsys_dict['CV_intrinsic'])]\n",
    "cv_bdtcut_err = [np.sqrt(x)/x for x in cv_bdtcut]\n",
    "\n",
    "plt.hist(bincenters_detsys, bins_detsys, weights=nueCC_detsys_dict['fractional_uncertainty'], histtype='step', \n",
    "         label='After BDT Cut (from 14712.2 GENIE/PPFX-tuned CV evts)', color='gray')\n",
    "\n",
    "plt.errorbar(bincenters_detsys, nueCC_detsys_dict['fractional_uncertainty'], fmt='none', \n",
    "             yerr=cv_bdtcut_err, color='gray')\n",
    "\n",
    "\n",
    "plt.hlines(np.average(nueCC_detsys_dict['fractional_uncertainty']), 0, 250, linestyle='--', \n",
    "           label='Avg = '+str(round(np.average(nueCC_detsys_dict['fractional_uncertainty']), 3)))\n",
    "\n",
    "plt.xlim(0, 250)\n",
    "plt.ylim(0, 0.33)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reconstructed X Position [cm]\", fontsize=14)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.title(\"FHC Run 1 & RHC Run 3 Det. Sys. ($\\\\nu_{e}$ CC Intrinsic Sample)\", fontsize=15)\n",
    "#plt.savefig(parameters(ISRUN3)['plots_path']+\"RHCRUN3DetSys.pdf\", transparent=True, bbox_inches='tight') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_detsys_dict = {\n",
    "    'fractional_uncertainty' : [np.average(nueCC_detsys_dict['fractional_uncertainty']) for x in range(len(bins))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "for i in range(len(bins)-1): \n",
    "        frac_cov[i][i] = np.average(nueCC_detsys_dict['fractional_uncertainty'])**2\n",
    "\n",
    "avg_detsys_dict['frac_cov'] = frac_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat Uncertainty (MC background) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't include EXT uncertainty \n",
    "# sum of the weights squared\n",
    "\n",
    "mc_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "mc_frac_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "mc_sumw2 = [a+b for a,b in zip(fhc_dict['mc_bkgd_sumw2'], rhc_dict['mc_bkgd_sumw2'])]\n",
    "evt_rate = [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])]\n",
    "\n",
    "fhc_mc_stat_percent_error = []\n",
    "rhc_mc_stat_percent_error = []\n",
    "\n",
    "# MC background stat uncertainty\n",
    "for i in range(len(bins)-1):\n",
    "    \n",
    "    mc_stat_cov[i][i] = mc_sumw2[i]\n",
    "    mc_frac_stat_cov[i][i] = mc_stat_cov[i][i]/ evt_rate[i]**2 \n",
    "    \n",
    "    fhc_mc_stat_percent_error.append(np.sqrt(fhc_dict['mc_bkgd_sumw2'][i]/fhc_dict['evt_rate'][i]**2))\n",
    "    rhc_mc_stat_percent_error.append(np.sqrt(rhc_dict['mc_bkgd_sumw2'][i]/rhc_dict['evt_rate'][i]**2))\n",
    "\n",
    "    \n",
    "mc_stat_percent_error = np.sqrt(np.diag(mc_frac_stat_cov))\n",
    "mc_stat_percent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=mc_stat_percent_error, color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_mc_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_mc_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "#plt.ylim(0, 0.05)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"MC Bkgd STAT Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat Uncertainty (EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXT uncertainty \n",
    "# sum of the weights squared\n",
    "\n",
    "ext_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "ext_frac_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "ext_sumw2 = [a+b for a,b in zip(fhc_dict['ext_sumw2'], rhc_dict['ext_sumw2'])]\n",
    "\n",
    "fhc_ext_stat_percent_error = []\n",
    "rhc_ext_stat_percent_error = []\n",
    "\n",
    "# MC background stat uncertainty\n",
    "for i in range(len(bins)-1):\n",
    "    \n",
    "    ext_stat_cov[i][i] = ext_sumw2[i]\n",
    "    ext_frac_stat_cov[i][i] = ext_stat_cov[i][i]/ evt_rate[i]**2 \n",
    "    \n",
    "    fhc_ext_stat_percent_error.append(np.sqrt(fhc_dict['ext_sumw2'][i]/fhc_dict['evt_rate'][i]**2))\n",
    "    rhc_ext_stat_percent_error.append(np.sqrt(rhc_dict['ext_sumw2'][i]/rhc_dict['evt_rate'][i]**2))\n",
    "    \n",
    "ext_stat_percent_error = np.sqrt(np.diag(ext_frac_stat_cov))\n",
    "ext_stat_percent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=ext_stat_percent_error, color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_ext_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_ext_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "#plt.ylim(0, 0.05)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"EXT STAT Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat Uncertainty (BEAM ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background subtracted event rate (use MC for closure test/fake data studies, beam ON count for real data result)\n",
    "\n",
    "print(\"Make sure to update to beam on statistics when using real data !\")\n",
    "    \n",
    "beamon_frac_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "fhc_beamon_stat_percent_error = []\n",
    "rhc_beamon_stat_percent_error = []\n",
    "    \n",
    "for i in range(len(bins)-1): \n",
    "    \n",
    "    beamon_frac_stat_cov[i][i] = evt_rate[i]/(evt_rate[i]**2)\n",
    "    \n",
    "    fhc_beamon_stat_percent_error.append(np.sqrt(fhc_dict['evt_rate'][i]/fhc_dict['evt_rate'][i]**2))\n",
    "    rhc_beamon_stat_percent_error.append(np.sqrt(rhc_dict['evt_rate'][i]/rhc_dict['evt_rate'][i]**2))\n",
    "\n",
    "beamon_stat_percent_error = np.sqrt(np.diag(beamon_frac_stat_cov))\n",
    "print(beamon_stat_percent_error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=beamon_stat_percent_error, color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_beamon_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_beamon_stat_percent_error, \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.65)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"Beam-On Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmatrix_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['response_matrix'], rhc_dict['response_matrix']): \n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc,v_rhc)]\n",
    "    rmatrix_variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"RESPONSE MATRIX VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_rmatrix_dict = calcCov(xvar, bins, fhc_dict['evt_rate'], fhc_dict['evt_rate'], \n",
    "                    fhc_dict['response_matrix'], plot=False, save=False) \n",
    "\n",
    "rhc_rmatrix_dict = calcCov(xvar, bins, rhc_dict['evt_rate'], rhc_dict['evt_rate'], \n",
    "                    rhc_dict['response_matrix'], plot=False, save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmatrix_dict = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    rmatrix_variations, plot=False, save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmatrix_dict['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=rmatrix_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_rmatrix_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_rmatrix_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.1)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"Response Matrix Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirt Uncertainty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(uncertainty_functions)\n",
    "from uncertainty_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "\n",
    "comb_v = [a+b for a,b in zip(fhc_dict['dirt'],rhc_dict['dirt'])]\n",
    "dirt_variations.append(comb_v)\n",
    "    \n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['cv_dirt'], rhc_dict['cv_dirt'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"DIRT VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_dirt_dict = dirt_unisim(xvar, bins, fhc_dict['evt_rate'], fhc_dict['cv_dirt'], 1.0, isrun3=False, plot=True, \n",
    "                               x_label=None, title=None)\n",
    "\n",
    "rhc_dirt_dict = dirt_unisim(xvar, bins, rhc_dict['evt_rate'], rhc_dict['cv_dirt'], 1.0, isrun3=True, plot=True, \n",
    "                               x_label=None, title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt_dict = dirt_unisim(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                        [a+b for a,b in zip(fhc_dict['cv_dirt'], rhc_dict['cv_dirt'])], \n",
    "                        1.0, plot=True, x_label=None, title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Combined\", \n",
    "         weights=dirt_dict['fractional_uncertainty'], color='black', linewidth=2)\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"FHC\", \n",
    "         weights=fhc_dirt_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), linewidth=2)\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"RHC\", \n",
    "         weights=rhc_dirt_dict['fractional_uncertainty'], \n",
    "         linestyle=(0, (1, 1)), color='orange', linewidth=2)\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "#plt.ylim(0, 0.1)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"Dirt Uncertainty\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POT counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_variations = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5)) \n",
    "\n",
    "for v_fhc, v_rhc in zip(fhc_dict['pot_counting'], rhc_dict['pot_counting']): \n",
    "    \n",
    "    comb_v = [a+b for a,b in zip(v_fhc,v_rhc)]\n",
    "    pot_variations.append(comb_v)\n",
    "    \n",
    "    plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, weights=comb_v,\n",
    "        histtype='step', color='cornflowerblue', linewidth=1)\n",
    "\n",
    "plt.hist(0.5*(np.array(bins)[1:]+np.array(bins)[:-1]), bins, \n",
    "        weights=[a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])],\n",
    "        histtype='step', color='black', linewidth=2) \n",
    "    \n",
    "plt.xlim(xlow, 2.5)\n",
    "plt.title(\"POT COUNTING VARIATIONS (FHC+RHC)\", fontsize=15)\n",
    "\n",
    "plt.xticks([0.02, 0.22, 0.42, 0.62, 0.82 , 1.22], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(x_label, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_dict = calcCov(xvar, bins, [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    [a+b for a,b in zip(fhc_dict['evt_rate'], rhc_dict['evt_rate'])], \n",
    "                    pot_variations, plot=False, save=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_dict['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Uncertainty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_cov_dict = {\n",
    "    'ppfx' : ppfx_dict['frac_cov'], \n",
    "    'beamline' : beamline_unisim_dict['frac_cov'], \n",
    "    'genie_ms' : genie_dict['frac_cov'], \n",
    "    'genie_us': genie_unisim_dict['frac_cov'], \n",
    "    'geant4' : geant4_dict['frac_cov'],\n",
    "    'detector' : avg_detsys_dict['frac_cov'], \n",
    "    'pot_counting' : pot_dict['frac_cov'], \n",
    "    'dirt' : dirt_dict['frac_cov'],\n",
    "    'mc_stat' : mc_frac_stat_cov, # background only \n",
    "    'ext_stat' : ext_frac_stat_cov, \n",
    "    'response_matrix' : rmatrix_dict['frac_cov']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_frac_cov, tot_abs_cov = plotFullCov(frac_cov_dict, xvar, evt_rate, bins, xlow, xhigh, x_ticks=x_ticks, save=False, \n",
    "                      axis_label='Reco '+x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ppfx & beamline geometry in quadrature\n",
    "frac_cov_dict['flux'] = [ [x+y for x,y in zip(a,b)] for a,b in zip(frac_cov_dict['ppfx'], frac_cov_dict['beamline'])]\n",
    "\n",
    "# add genie in quadrature\n",
    "frac_cov_dict['genie_all'] = [ [x+y for x,y in zip(a,b)] for a,b in zip(frac_cov_dict['genie_ms'], frac_cov_dict['genie_us'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAKE sure to update to include beam on stat!\")\n",
    "frac_cov_dict['stat_all'] = [ [x+y+z for x,y,z in zip(b,c,d)] for b,c,d in zip( frac_cov_dict['response_matrix'], frac_cov_dict['mc_stat'], frac_cov_dict['ext_stat'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean away nans\n",
    "v = np.array(tot_frac_cov)\n",
    "v[np.isnan(v)] = 0\n",
    "tot_frac_cov = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_unc_dict = {\n",
    "    'flux' : np.sqrt(np.diagonal(frac_cov_dict['flux'])), \n",
    "    'genie' : np.sqrt(np.diagonal(frac_cov_dict['genie_all'])), \n",
    "    'geant4' : np.sqrt(np.diagonal(frac_cov_dict['geant4'])),\n",
    "    'detector' : np.sqrt(np.diagonal(frac_cov_dict['detector'])), \n",
    "    'pot_counting' : np.sqrt(np.diagonal(frac_cov_dict['pot_counting'])), \n",
    "    'dirt' : np.sqrt(np.diagonal(frac_cov_dict['dirt'])),\n",
    "    'stat' : np.sqrt(np.diagonal(frac_cov_dict['stat_all'])), # does not include beam on STAT \n",
    "    'total' : np.sqrt(np.diagonal(tot_frac_cov))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_unc = [0 for i in range(len(bins)-1)]\n",
    "test = []\n",
    "\n",
    "for source in frac_unc_dict.keys(): \n",
    "    \n",
    "    if source=='total': \n",
    "        continue\n",
    "    \n",
    "    test.append(frac_unc_dict[source][0])\n",
    "    \n",
    "    # square the list \n",
    "    squared = [x**2 for x in frac_unc_dict[source]]\n",
    "    \n",
    "    # add in quadrature \n",
    "    tot_unc = [a+b for a,b in zip(tot_unc, squared)]\n",
    "   \n",
    "tot_unc = np.sqrt(np.array(tot_unc))\n",
    "print(tot_unc)\n",
    "\n",
    "frac_unc_dict['total'] = tot_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "# TOTAL \n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Total\",\n",
    "        weights=frac_unc_dict['total'], linewidth=1.5, color='black')\n",
    "\n",
    "# FLUX\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Flux\", \n",
    "         weights=frac_unc_dict['flux'], color='royalblue')\n",
    "\n",
    "# CROSS SECTION MODELS \n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"GENIE\", \n",
    "         weights=frac_unc_dict['genie'], color='goldenrod')\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"GEANT4\", \n",
    "         weights=frac_unc_dict['geant4'], color='green')\n",
    "\n",
    "# DETECTOR \n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Detector\", \n",
    "         weights=frac_unc_dict['detector'], color='crimson')\n",
    "\n",
    "# POT COUNTING \n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"POT counting\",\n",
    "        weights=frac_unc_dict['pot_counting'], color='purple')\n",
    "\n",
    "# DIRT \n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Dirt\",\n",
    "        weights=frac_unc_dict['dirt'], color='brown')\n",
    "\n",
    "# STATISTICAL \n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Response matrix\",\n",
    "        weights=np.sqrt(np.diagonal(frac_cov_dict['response_matrix'])))\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='step', range=[bins[0], bins[-1]], label=\"Stat (MC+EXT)\",\n",
    "        weights=frac_unc_dict['stat'], color='hotpink')\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.xlabel(\"Reco \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Fractional Uncertainty\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.legend(fontsize=13, frameon=False, ncol=3)\n",
    "plt.title(\"FHC+RHC Background-Subtracted Event Rate\", fontsize=16)\n",
    "\n",
    "#plt.savefig(plots_path+xvar+\"_RHC_FracUncertainty.pdf\", transparent=True, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smearing & efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smearing/FHC_July15.json') as f_fhc:\n",
    "    fhc_smearing_dict = json.load(f_fhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smearing/RHC_July15.json') as f_rhc:\n",
    "    rhc_smearing_dict = json.load(f_rhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhc_smearing_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = []\n",
    "\n",
    "for x in range(len(bincenters)): \n",
    "    binwidth.append(round(abs(x_ticks[x+1]-x_ticks[x])/2, 2))\n",
    "    \n",
    "binwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# fhc efficiency \n",
    "fhc_true_generated = fhc_smearing_dict['true_generated']\n",
    "fhc_true_selected = fhc_smearing_dict['true_selected']\n",
    "\n",
    "fhc_eff = [a/b for a,b in zip(fhc_true_selected, fhc_true_generated)]\n",
    "fhc_eff_err = [ np.sqrt( (x*(1-x)) / y ) for x,y in zip(fhc_eff,fhc_true_generated) ]\n",
    "\n",
    "print('FHC Efficiency (%) = ', [round(x,3)*100 for x in fhc_eff])\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "# rhc efficiency \n",
    "rhc_true_generated = rhc_smearing_dict['true_generated']\n",
    "rhc_true_selected = rhc_smearing_dict['true_selected']\n",
    "\n",
    "rhc_eff = [a/b for a,b in zip(rhc_true_selected, rhc_true_generated)]\n",
    "rhc_eff_err = [ np.sqrt( (x*(1-x)) / y ) for x,y in zip(rhc_eff,rhc_true_generated) ]\n",
    "\n",
    "print('RHC Efficiency (%) = ', [round(x,3)*100 for x in rhc_eff])\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "# combined efficiency \n",
    "\n",
    "true_generated = [a+b for a,b in zip(fhc_smearing_dict['true_generated'], rhc_smearing_dict['true_generated'])]\n",
    "true_selected = [a+b for a,b in zip(fhc_smearing_dict['true_selected'], rhc_smearing_dict['true_selected'])]\n",
    "\n",
    "eff = [a/b for a,b in zip(true_selected, true_generated)]\n",
    "eff_err = [ np.sqrt( (x*(1-x)) / y ) for x,y in zip(eff,true_generated) ]\n",
    "\n",
    "print('Combined Efficiency (%) = ', [round(x,3)*100 for x in eff])\n",
    "\n",
    "\n",
    "# Plot \n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))  \n",
    "\n",
    "plt.errorbar(bincenters, fhc_eff, yerr=fhc_eff_err, xerr=binwidth, label=\"FHC\", fmt='.')\n",
    "plt.errorbar(bincenters, rhc_eff, yerr=rhc_eff_err, xerr=binwidth, label=\"RHC\", fmt='.')\n",
    "\n",
    "plt.errorbar(bincenters, eff, yerr=eff_err, xerr=binwidth, label=\"FHC+RHC\", fmt='.', color='black')\n",
    "\n",
    "plt.xticks(x_ticks[:-1], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.ylim(0, .25)\n",
    "\n",
    "plt.xlabel(\"True \" + x_label, fontsize=15)\n",
    "plt.ylabel(\"Selected / Generated\", fontsize=15)\n",
    "\n",
    "plt.xlim(bins[0], xhigh)\n",
    "\n",
    "plt.legend(fontsize=14, frameon=False, ncol=3)\n",
    "plt.title(\"Efficiency\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_matrix = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "for col in range(len(bins)-1):\n",
    "    for row in range(len(bins)-1):\n",
    "\n",
    "        response_matrix[row][col] = (fhc_smearing_dict['smearing_matrix'][row][col] + rhc_smearing_dict['smearing_matrix'][row][col]) / true_generated[col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 9))\n",
    "\n",
    "plt.pcolor(bins, bins, response_matrix, cmap='OrRd', vmin=0.00000000001, edgecolors='k')\n",
    "\n",
    "plt.title('FHC+RHC Smearing & Efficiency', fontsize=15)\n",
    "\n",
    "plt.xticks(x_ticks, fontsize=14)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.yticks(x_ticks, fontsize=14)\n",
    "\n",
    "plt.xlim(xlow, xhigh)\n",
    "plt.ylim(xlow, xhigh)\n",
    "            \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.xlabel('True Shower Energy [GeV]', fontsize=15)\n",
    "plt.ylabel('Reco Shower Energy [GeV]', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that this is constructed properly \n",
    "# sum of the columns should equal the combined efficiency \n",
    "\n",
    "for i in range(len(bincenters)): # loop over columns\n",
    "\n",
    "    x = 0 \n",
    "    for j in range(len(bincenters)): # sum up the rows\n",
    "    \n",
    "        x += response_matrix[j][i]\n",
    "\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV event rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "plt.hist(bincenters, bins, color='orange', label='True (Generated)', alpha=0.4, \n",
    "         weights=[a+b for a,b in zip(fhc_smearing_dict['true_generated'],rhc_smearing_dict['true_generated'])])\n",
    "\n",
    "plt.hist(bincenters, bins, color='blue', label='Reco (Selected)', alpha=0.4, weights=evt_rate)\n",
    "\n",
    "plt.legend(fontsize=13)\n",
    "plt.title('FHC+RHC Input Signal Distributions', fontsize=16)\n",
    "\n",
    "#plt.ylim(0, 5E-40)\n",
    "plt.xlim(0, 2.5)\n",
    "\n",
    "plt.xlabel(\"Shower Energy [GeV]\", fontsize=15)\n",
    "    \n",
    "plt.xticks(x_ticks, fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "#plt.savefig(plots_path+\"_InputSignalDistributions_ElectronEnergy.pdf\", transparent=True, bbox_inches='tight') \n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to unfolding file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "\n",
    "if save: \n",
    "    print(\"Make sure to update file name!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save: \n",
    "    \n",
    "    # covariance matrix \n",
    "    hcov = TH2D(\"hcov_tot\", \"Covariance Matrix vs. Reco \"+x_label, \n",
    "                len(bins)-1, np.array(bins), len(bins)-1, np.array(bins))\n",
    "\n",
    "    for i in range(len(bincenters)): # i = row (y)\n",
    "        for j in range(len(bincenters)): # j = column (x) \n",
    "\n",
    "            hcov.Fill(bincenters[j], bincenters[i], tot_abs_cov[i][j]) \n",
    "\n",
    "    # true signal distribution\n",
    "    htrue_signal = TH1F(\"htrue_signal\", \"Generated MC Signal vs. True \"+x_label+\" (\"+true_var+\")\", len(bins)-1, np.array(bins))\n",
    "\n",
    "    for i in range(len(bincenters)): \n",
    "        htrue_signal.Fill(bincenters[i], true_generated[i])\n",
    "        \n",
    "    # reco distribution (MC or data)\n",
    "    hreco = TH1D(\"hmeas\", \"Selected MC Signal vs. Reco \"+x_label+\" (\"+xvar+\")\", len(bins)-1, np.array(bins))\n",
    "\n",
    "    for i in range(len(bincenters)): \n",
    "        hreco.Fill(bincenters[i], evt_rate[i])\n",
    "    \n",
    "    # response matrix \n",
    "    r = TH2D(\"hR\", \"Response Matrix\", len(bins)-1, np.array(bins), len(bins)-1, np.array(bins))\n",
    "    for i in range(len(bincenters)): # i = column (x)\n",
    "        for j in range(len(bincenters)): # j = row (y) \n",
    "            \n",
    "            r.Fill(bincenters[i], bincenters[j], response_matrix[i][j]) \n",
    "            \n",
    "    f = ROOT.TFile.Open(\"/uboone/data/users/kmiller/uBNuMI_CCNp/unfolding/WSVD_\"+xvar+\"_Combined_July15.root\", \"RECREATE\")\n",
    "    \n",
    "    f.cd()\n",
    "    \n",
    "    hcov.Write()\n",
    "    htrue_signal.Write()\n",
    "    hreco.Write()\n",
    "    r.Write()\n",
    "    \n",
    "    f.Close()\n",
    "\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
