{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'backend_functions')\n",
    "\n",
    "import selection_functions as sf\n",
    "\n",
    "import importlib\n",
    "\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT\n",
    "from ROOT import TH1F, TH2F, TDirectory, TH1D\n",
    "\n",
    "import top \n",
    "from top import *\n",
    "\n",
    "importlib.reload(sf)\n",
    "from selection_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISRUN3 = False\n",
    "NUE_INTRINSIC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ISRUN3:\n",
    "    import NuMIGeoWeights\n",
    "    importlib.reload(NuMIGeoWeights)\n",
    "\n",
    "    # the default option is FHC, RHC needs different arguments - need to create still \n",
    "    numiBeamlineGeoWeights = NuMIGeoWeights.NuMIGeoWeights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_path = parameters(ISRUN3)['plots_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POT normalization factors\n",
    "\n",
    "\n",
    "overlay_pot =  parameters(ISRUN3)['overlay_pot']   \n",
    "dirt_pot = parameters(ISRUN3)['dirt_pot'] \n",
    "beamon_pot = parameters(ISRUN3)['beamon_pot'] \n",
    "\n",
    "\n",
    "beamon_ntrig =  parameters(ISRUN3)['beamon_ntrig'] \n",
    "beamoff_ntrig = parameters(ISRUN3)['beamoff_ntrig'] \n",
    "    \n",
    "if NUE_INTRINSIC: \n",
    "    nue_intrinsic_pot = parameters(ISRUN3)['intrinsic_pot'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "DATA = \"\"\n",
    "EXT = \"\"\n",
    "OVRLY  = \"\"\n",
    "DRT = \"\"\n",
    "NUE = \"\"\n",
    "\n",
    "# old paths \n",
    "# '/uboone/data/users/kmistry/work/MCC9/searchingfornues/'\n",
    "# path = '/uboone/data/users/kmiller/ntuples/run1/\n",
    "# path = '/uboone/data/users/kmiller/ntuples/run1/qualcuts/'\n",
    "\n",
    "path = parameters(ISRUN3)['cv_ntuple_path']\n",
    "print('path = ', path)\n",
    "\n",
    "if not ISRUN3: \n",
    "    \n",
    "    #path = '/uboone/data/users/kmiller/uBNuMI_CCNp/ntuples/run1/nuepresel/' # includes shr_energy_tot_cali cut\n",
    "    \n",
    "    # Run 1 FHC \n",
    "    OVRLY = 'neutrinoselection_filt_run1_overlay_v7'\n",
    "    EXT = 'neutrinoselection_filt_run1_beamoff_v5'\n",
    "    DATA = 'neutrinoselection_filt_run1_beamon_beamgood_v5'\n",
    "    DRT = 'prodgenie_numi_uboone_overlay_dirt_fhc_mcc9_run1_v28_all_snapshot'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'neutrinoselection_filt_run1_overlay_intrinsic_v7' \n",
    "\n",
    "\n",
    "else: \n",
    "    \n",
    "    #path = '/uboone/data/users/kmiller/uBNuMI_CCNp/ntuples/run3b/nuepresel/'\n",
    "    \n",
    "    # Run 3 RHC\n",
    "    OVRLY = 'neutrinoselection_filt_run3b_overlay_v7'\n",
    "    DATA = 'neutrinoselection_filt_run3b_beamon_beamgood_v5'\n",
    "    EXT = 'neutrinoselection_filt_run3b_beamoff_v5'\n",
    "    DRT = 'neutrinoselection_filt_run3b_dirt_overlay_v6'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'neutrinoselection_filt_run3b_overlay_intrinsic_v7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlay = uproot.open(path+OVRLY+\".root\")[fold][tree]\n",
    "data = uproot.open(path+DATA+\".root\")[fold][tree]\n",
    "ext = uproot.open(path+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(path+DRT+\".root\")[fold][tree]  \n",
    "\n",
    "uproot_v = [overlay,data,ext,dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue = uproot.open(path+NUE+\".root\")[fold][tree]\n",
    "    uproot_v.append(nue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"trk_score_v\", \n",
    "    \"shr_tkfit_dedx_Y\", \n",
    "    \"n_tracks_contained\", \n",
    "    \"NeutrinoEnergy2\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\",\n",
    "    \"trkshrhitdist2\",\n",
    "    \"n_showers_contained\", \n",
    "    \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_score\", \n",
    "    \"trk_energy\", \n",
    "    \"tksh_distance\", \"tksh_angle\",\n",
    "    \"shr_energy_tot_cali\", \"shr_energy_cali\", \n",
    "    \"nslice\", \n",
    "    \"contained_fraction\",\n",
    "    \"shrmoliereavg\", \"shr_px\", \"shr_py\", \"shr_pz\"\n",
    "]\n",
    "\n",
    "# MC only variables\n",
    "mc_var = [\"nu_pdg\", \"shr_theta\", \"true_e_visible\", \"ccnc\", \n",
    "          \"nproton\", \"nu_purity_from_pfp\", \"nu_e\", \"npi0\", \"npion\",\n",
    "          \"true_nu_vtx_x\", \"true_nu_vtx_y\" , \"true_nu_vtx_z\", \n",
    "          \"weightTune\", \"weightSpline\", \"weightSplineTimesTune\", \n",
    "          \"true_nu_px\", \"true_nu_py\", \"true_nu_pz\", \n",
    "          \"elec_e\", \"proton_e\", \"mc_px\", \"mc_py\", \"mc_pz\", \"elec_px\", \"elec_py\", \"elec_pz\", \n",
    "          \"swtrig_pre\", \"ppfx_cv\", \"mc_pdg\", \"opening_angle\"]\n",
    "\n",
    "sys_genie = [\"weightsGenie\", \"weightsReint\", \n",
    "             \"knobRPAup\", \"knobRPAdn\", \n",
    "             \"knobCCMECup\", \"knobCCMECdn\", \n",
    "             \"knobAxFFCCQEup\", \"knobAxFFCCQEdn\", \n",
    "             \"knobVecFFCCQEup\", \"knobVecFFCCQEdn\", \n",
    "             \"knobDecayAngMECup\", \"knobDecayAngMECdn\", \n",
    "             \"knobThetaDelta2Npiup\", \"knobThetaDelta2Npidn\", \n",
    "             \"knobThetaDelta2NRadup\", \"knobThetaDelta2NRaddn\", \n",
    "             #\"knobRPA_CCQE_Reducedup\", \"knobRPA_CCQE_Reduceddn\", \n",
    "             \"knobNormCCCOHup\", \"knobNormCCCOHdn\", \n",
    "             \"knobNormNCCOHup\", \"knobNormNCCOHdn\",    \n",
    "             \"knobxsr_scc_Fv3up\", \"knobxsr_scc_Fv3dn\", \n",
    "             \"knobxsr_scc_Fa3up\", \"knobxsr_scc_Fa3dn\"]\n",
    "\n",
    "sys_flux = ['weightsPPFX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERLAY \n",
    "overlay = overlay.pandas.df(variables + mc_var + sys_genie + sys_flux, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRT \n",
    "dirt = dirt.pandas.df(variables + mc_var + sys_genie[:-4] + sys_flux, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTRINSIC \n",
    "if NUE_INTRINSIC: \n",
    "    nue = nue.pandas.df(variables + mc_var + sys_genie + sys_flux, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAM ON \n",
    "data = data.pandas.df(variables, flatten=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAM OFF\n",
    "ext = ext.pandas.df(variables, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalize the columns\n",
    "\n",
    "for var in mc_var+sys_genie+sys_flux: \n",
    "    data[var] = np.nan\n",
    "    ext[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is dirt bool\n",
    "\n",
    "overlay['isDirt'] = False\n",
    "dirt['isDirt'] = True\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['isDirt'] = False\n",
    "    \n",
    "data['isDirt'] = np.nan\n",
    "ext['isDirt'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# code from Giuseppe!\n",
    "#LLR-PID : log likelihood ratio particle ID \n",
    "\n",
    "df_v = [overlay,data,ext,dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    df_v.append(nue)\n",
    "    \n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "\n",
    "    df['NeutrinoEnergy2_GeV'] = df['NeutrinoEnergy2']/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = [overlay, dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    mc_df.append(nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    # is signal bool \n",
    "    df['is_signal'] = np.where((df.swtrig_pre == 1) \n",
    "                             & (df.nu_pdg==12) & (df.ccnc==0) & (df.nproton>0) & (df.npion==0) & (df.npi0==0)\n",
    "                             & (10 <= df.true_nu_vtx_x) & (df.true_nu_vtx_x <= 246)\n",
    "                             & (-106 <= df.true_nu_vtx_y) & (df.true_nu_vtx_y <= 106)\n",
    "                             & (10 <= df.true_nu_vtx_z) & (df.true_nu_vtx_z <= 1026), True, False)\n",
    "    \n",
    "    # Add truth level theta & phi angles (detector & beam coordinates)\n",
    "    df = addAngles(df)\n",
    "    \n",
    "    \n",
    "    df['weightsPPFX'] = df['weightsPPFX']/1000\n",
    "    df['weightsReint'] = df['weightsReint']/1000\n",
    "    df['weightsGenie'] = df['weightsGenie']/1000\n",
    "    \n",
    "    \n",
    "    # add beamline geometry weights\n",
    "    df['weightsNuMIGeo'] = df.apply( lambda x: numiBeamlineGeoWeights.calculateGeoWeight(x['nu_pdg'],x['nu_e'],x['thbeam']) , axis=1)\n",
    "    \n",
    "    \n",
    "    # add genie unisim weights \n",
    "    if i==1: \n",
    "        universes = []\n",
    "        for evt in df[sys_genie[2:-4]].values: \n",
    "            if np.all(evt == 1): \n",
    "                universes.append( [0 for j in range(len(sys_genie[2:]))] )\n",
    "                \n",
    "            else: \n",
    "                universes.append( list(evt) + [0, 0, 0, 0] ) # dirt doesn't have variations for the last 4 knobs \n",
    "        \n",
    "    else: \n",
    "        universes = []\n",
    "        for evt in df[sys_genie[2:]].values: \n",
    "            if np.all(evt == 1): \n",
    "                universes.append( [0 for j in range(len(sys_genie[2:]))] )  # don't include CV neutrinos \n",
    "\n",
    "            else: \n",
    "                universes.append( evt )\n",
    "\n",
    "        \n",
    "    df['weightsGenieUnisim'] = universes\n",
    "    \n",
    "    # for easier handling \n",
    "    df['weightsGenieUnisim'] = df['weightsGenieUnisim'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframes equal # of columns \n",
    "\n",
    "data['is_signal'] = np.nan\n",
    "ext['is_signal'] = False\n",
    "\n",
    "nan_var = ['thdet', 'phidet', 'true_nu_px_beam', 'true_nu_py_beam', 'true_nu_pz_beam', \n",
    "           'thbeam', 'phibeam','weightsNuMIGeo', 'weightsGenieUnisim']\n",
    "\n",
    "for var in mc_var+sys_genie+sys_flux+nan_var: \n",
    "    data[var] = np.nan\n",
    "    ext[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some checks \n",
    "print(len(nue.query('is_signal==True'))==len(nue.query(signal)))\n",
    "print(len(nue.query('is_signal==False'))==len(nue.query(not_signal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean bad weights & values \n",
    "\n",
    "for i,df in enumerate(mc_df):\n",
    "     \n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.  \n",
    "\n",
    "    \n",
    "    for ievt in range(df.shape[0]):\n",
    "        \n",
    "        # GENIE MULTISIMS\n",
    "        \n",
    "        # check for NaNs separately        \n",
    "        if np.isnan(df['weightsGenie'].iloc[ievt]).any() == True: \n",
    "            df['weightsGenie'].iloc[ievt][ np.isnan(df['weightsGenie'].iloc[ievt]) ] = 1.\n",
    "            \n",
    "        reweightCondition = ((df['weightsGenie'].iloc[ievt] > 60) | (df['weightsGenie'].iloc[ievt] < 0)  | \n",
    "                             (df['weightsGenie'].iloc[ievt] == np.inf) | (df['weightsGenie'].iloc[ievt] == np.nan))\n",
    "        df['weightsGenie'].iloc[ievt][ reweightCondition ] = 1.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsGenie'].iloc[ievt]): \n",
    "            df['weightsGenie'].iloc[ievt] = [1.0 for k in range(600)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # RE-INTERACTION WEIGHTS\n",
    "        \n",
    "        # check for NaNs separately        \n",
    "        if np.isnan(df['weightsReint'].iloc[ievt]).any() == True: \n",
    "            df['weightsReint'].iloc[ievt][ np.isnan(df['weightsReint'].iloc[ievt]) ] = 1.\n",
    "        \n",
    "        reweightCondition2 = ((df['weightsReint'].iloc[ievt] > 60) | (df['weightsReint'].iloc[ievt] < 0)   |\n",
    "                             (df['weightsReint'].iloc[ievt] == np.inf))\n",
    "        df['weightsReint'].iloc[ievt][ reweightCondition2 ] = 1.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsReint'].iloc[ievt]): \n",
    "            df['weightsReint'].iloc[ievt] = [1.0 for k in range(1000)]\n",
    "            \n",
    "            \n",
    "            \n",
    "        # GENIE UNISIMS \n",
    "        \n",
    "        # check for NaNs separately\n",
    "        if np.isnan(df['weightsGenieUnisim'].iloc[ievt]).any() == True: \n",
    "            df['weightsGenieUnisim'].iloc[ievt][ np.isnan(df['weightsGenieUnisim'].iloc[ievt]) ] = 1.\n",
    "        \n",
    "        reweightCondition3 = ((df['weightsGenieUnisim'].iloc[ievt] == np.inf) | (df['weightsGenieUnisim'].iloc[ievt] > 60) | \n",
    "                              (df['weightsGenieUnisim'].iloc[ievt] < 0))\n",
    "        df['weightsGenieUnisim'].iloc[ievt][ reweightCondition3 ] = 1.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsGenieUnisim'].iloc[ievt]): \n",
    "            df['weightsGenieUnisim'].iloc[ievt] = [1.0 for k in range(len(sys_genie[2:]))]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pot scaling weights \n",
    "\n",
    "dirt_tune = parameters(ISRUN3)['dirt_tune']\n",
    "ext_tune = parameters(ISRUN3)['ext_tune']\n",
    "    \n",
    "##############################################\n",
    "# SCALE TO BEAM ON POT\n",
    "overlay_scale_to_data = beamon_pot/overlay_pot\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue_scale_to_data = beamon_pot/nue_intrinsic_pot\n",
    "\n",
    "dirt_scale_to_data = dirt_tune*(beamon_pot/dirt_pot)\n",
    "beamoff_scale_to_data = ext_tune*(beamon_ntrig/beamoff_ntrig) # scale factor to beam on POT\n",
    "\n",
    "overlay['pot_scale'] = overlay_scale_to_data\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['pot_scale'] = nue_scale_to_data\n",
    "    \n",
    "dirt['pot_scale'] = dirt_scale_to_data\n",
    "ext['pot_scale'] = beamoff_scale_to_data\n",
    "data['pot_scale'] = [1 for x in range(len(data))]\n",
    "\n",
    "##############################################\n",
    "# SCALE TO OVERLAY\n",
    "\n",
    "dirt_scale_to_overlay = dirt_tune*(overlay_pot/dirt_pot)\n",
    "beamoff_scale_to_overlay = ext_tune*((overlay_pot/beamon_pot)*(beamon_ntrig/beamoff_ntrig))\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue_scale_to_overlay = overlay_pot/nue_intrinsic_pot\n",
    "\n",
    "overlay['pot_scale_overlay'] = [1 for x in range(len(overlay))]\n",
    "if NUE_INTRINSIC: \n",
    "    nue['pot_scale_overlay'] = nue_scale_to_overlay\n",
    "    \n",
    "dirt['pot_scale_overlay'] = dirt_scale_to_overlay\n",
    "ext['pot_scale_overlay'] = beamoff_scale_to_overlay\n",
    "data['pot_scale_overlay'] = [1 for x in range(len(data))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total weights \n",
    "\n",
    "# combined genie * POT weight * flux weight \n",
    "# ext gets POT weight only \n",
    "\n",
    "################################################################\n",
    "# totweight_data scales to BEAMON\n",
    "\n",
    "# tuned\n",
    "overlay['totweight_data'] = overlay['pot_scale']*overlay['ppfx_cv']*overlay['weightSplineTimesTune']\n",
    "dirt['totweight_data'] = dirt['pot_scale']*dirt['ppfx_cv']*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['totweight_data'] = nue['pot_scale']*nue['ppfx_cv']*nue['weightSplineTimesTune']\n",
    "\n",
    "\n",
    "################################################################\n",
    "# totweight_overlay scales to STANDARD OVERLAY\n",
    "\n",
    "# tuned\n",
    "overlay['totweight_overlay'] = overlay['ppfx_cv']*overlay['weightSplineTimesTune']\n",
    "dirt['totweight_overlay'] = dirt['pot_scale_overlay']*dirt['ppfx_cv']*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC:\n",
    "    nue['totweight_overlay'] = nue['pot_scale_overlay']*nue['ppfx_cv']*nue['weightSplineTimesTune']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalize the columns\n",
    "\n",
    "new_var = ['totweight_data', 'totweight_overlay']\n",
    "\n",
    "for var in new_var: \n",
    "    for df in [data, ext]: \n",
    "        df[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUE_INTRINSIC: \n",
    "    \n",
    "    # intrinsic sample contains in AV TPC events ONLY, & only CC events (overlay is entire cryo)\n",
    "    in_AV_query = \"-1.55<=true_nu_vtx_x<=254.8 and -116.5<=true_nu_vtx_y<=116.5 and 0<=true_nu_vtx_z<=1036.8\"\n",
    "    \n",
    "    # remove the nue/nuebar CC in overlay\n",
    "    nueCC_query = 'abs(nu_pdg)==12 and ccnc==0 and '+in_AV_query\n",
    "    print(\"# of nueCC in AV in overlay sample = \"+str(len(overlay.query(nueCC_query))))\n",
    "    len1 = len(overlay)\n",
    "    \n",
    "    idx = overlay.query(nueCC_query).index\n",
    "    overlay.drop(idx, inplace=True)\n",
    "    len2 = len(overlay) \n",
    "    print(\"# of nueCC in AV dropped in overlay = \"+str(len1-len2))\n",
    "    \n",
    "    # then add in nue_intrinsic \n",
    "    overlay = pd.concat([overlay,nue], ignore_index=True)\n",
    "\n",
    "    # from here on out everything else should be the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine overlay + dirt as MC \n",
    "mc = pd.concat([overlay.query('swtrig_pre==1'),dirt.query('swtrig_pre==1')], ignore_index=True, sort=True)\n",
    "\n",
    "# separate by in/out FV & cosmic\n",
    "infv = mc.query(in_fv_query)#+' and nu_purity_from_pfp>0.5')\n",
    "#cosmic = mc.query(in_fv_query+' and nu_purity_from_pfp<=0.5')\n",
    "outfv = mc.query(out_fv_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check that everything is accounted for \n",
    "print(len(mc)==len(infv)+len(outfv))#+len(cosmic))\n",
    "\n",
    "if not (len(mc)==len(infv)+len(outfv)): #+len(cosmic)): \n",
    "    \n",
    "    d = len(mc) - (len(infv)+len(outfv))#+len(cosmic))\n",
    "    print(d)\n",
    "    \n",
    "    m = pd.concat([infv, outfv]) #pd.concat([infv, cosmic, outfv])\n",
    "    diff = np.setdiff1d(list(mc.index),list(m.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_signal_weighted = np.nansum(mc.query('is_signal==True')['totweight_data'])\n",
    "print('total signal events in FV  = '+ str(tot_signal_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 main categories: \n",
    "\n",
    "# infv - overlay & dirt events with truth vtx in FV \n",
    "# outfv - overlay & dirt events with truth vtx in FV that are classified as neutrinos\n",
    "# cosmic - overlay & dirt events with true vtx in FV that get misclassified as cosmic \n",
    "# ext - beam OFF data\n",
    "# data - beam ON data \n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"infv\": infv, \n",
    "    \"outfv\": outfv, \n",
    "    #\"cosmic\": cosmic, \n",
    "    \"ext\": ext, \n",
    "    \"data\": data\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preselection \n",
    "\n",
    "PRE_QUERY = 'nslice==1' # \n",
    "PRE_QUERY += ' and ' + reco_in_fv_query \n",
    "PRE_QUERY += ' and contained_fraction>0.9' \n",
    "PRE_QUERY += ' and shr_energy_tot_cali>0.07'\n",
    "\n",
    "PRE_QUERY += ' and n_tracks_contained>0'\n",
    "PRE_QUERY += ' and trk_energy>0.04' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new optimized selection by Kaushal \n",
    "\n",
    "SEL_QUERY = PRE_QUERY\n",
    "\n",
    "SEL_QUERY += ' and shr_score<0.125'\n",
    "SEL_QUERY += ' and shrmoliereavg < 8'\n",
    "SEL_QUERY += ' and trkpid<0'\n",
    "\n",
    "SEL_QUERY += ' and n_showers_contained == 1'\n",
    "SEL_QUERY += ' and shr_tkfit_dedx_Y<4'\n",
    "\n",
    "if not ISRUN3: \n",
    "    SEL_QUERY += ' and tksh_distance<5'\n",
    "    # SEL_QUERY += ' and -0.9<tksh_angle<0.8'\n",
    "\n",
    "else: \n",
    "    SEL_QUERY += ' and tksh_distance<4'\n",
    "    # SEL_QUERY += ' and -0.8<tksh_angle<0.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the datasets \n",
    "\n",
    "selection_variables = ['nslice', \"reco_nu_vtx_sce_x\", \"reco_nu_vtx_sce_y\", \"reco_nu_vtx_sce_z\", \"contained_fraction\", \n",
    "                      'shr_energy_tot_cali', 'n_tracks_contained', 'trk_energy', 'shr_score', 'shrmoliereavg', 'trkpid', \n",
    "                      'n_showers_contained', 'shr_tkfit_dedx_Y', 'tksh_distance', 'tksh_angle']\n",
    "\n",
    "for key in datasets.keys(): \n",
    "    \n",
    "    df = datasets[key].copy()\n",
    "    \n",
    "    for column in selection_variables:\n",
    "        df.loc[(df[column] < -1.0e37) | (df[column] > 1.0e37), column] = np.nan\n",
    "        \n",
    "    datasets[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projected event distribution \n",
    "\n",
    "x = plot_mc('nu_e', 20, 0, 5, SEL_QUERY, datasets, ISRUN3, norm='data', pot='$2\\\\times10^{20}$', \n",
    "            x_label=\"True Neutrino Energy [GeV]\", save=False, ymax=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cuts for selection performance plot \n",
    "# updated for modified signal definition\n",
    "\n",
    "cuts = ['nslice==1',  \n",
    "        reco_in_fv_query, \n",
    "        'contained_fraction>0.9',  \n",
    "        'shr_energy_tot_cali>0.07', \n",
    "        'n_tracks_contained>0',\n",
    "        'trk_energy>0.04', \n",
    "        'shr_score<0.125', \n",
    "        'shrmoliereavg<8', \n",
    "        'trkpid<0', \n",
    "        'n_showers_contained==1', \n",
    "        'shr_tkfit_dedx_Y<4']\n",
    "\n",
    "if not ISRUN3: \n",
    "    cuts.append('tksh_distance<5')\n",
    "    #cuts.append('-0.9<tksh_angle<0.8')\n",
    "\n",
    "else: \n",
    "    cuts.append('tksh_distance<4')\n",
    "    #cuts.append('-0.8<tksh_angle<0.8')\n",
    "    \n",
    "    \n",
    "cut_names = ['Slice ID', \"Reco'd in FV\", 'Containment', \"Tot. Shr Energy\", \n",
    "             \"# Cont. Tracks\",\"Track Energy\", \n",
    "             'Shr Score', 'Shr Moliere Angle', 'Trk PID', '# Shrs', 'dE/dx (Y plane)', \n",
    "             'Trk/Shr Distance']#, 'Trk/Shr Angle']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = selection_performance(cuts, datasets, 'totweight_overlay', generated_signal(ISRUN3, 'nu_e', 1, 0, 20), \n",
    "                             ISRUN3)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eff('nu_e', 6, 0, 6, SEL_QUERY, datasets, ISRUN3, x_label='True Neutrino Energy [GeV]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purity & efficiency as a function of cut \n",
    "\n",
    "pur_cut = perf['purity (%)']*.01\n",
    "eff_cut = perf['efficiency (%)']*.01\n",
    "rel_eff_cut = perf['rel. eff. (%)']*.01\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(list(range(len(pur_cut))), pur_cut, '-o', color='firebrick', \n",
    "         label='Purity', markersize=3, linewidth=2)\n",
    "plt.plot(list(range(len(pur_cut))), eff_cut, '-o', color='seagreen', \n",
    "         label='Efficiency', markersize=3, linewidth=2)\n",
    "plt.plot(list(range(len(pur_cut))), rel_eff_cut, '-o', color='goldenrod', \n",
    "         label='Relative Efficiency', markersize=3, linewidth=2)\n",
    "\n",
    "plt.grid(linestyle=\":\")\n",
    "\n",
    "plt.xticks(list(range(12)), cut_names, ha='right', fontsize=12)\n",
    "plt.xticks(rotation=40)\n",
    "plt.yticks([0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1],  fontsize=12)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.32, 0.37), fontsize=15)\n",
    "\n",
    "plt.title(\"Selection Performance\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality cuts\n",
    "BDT_PRE_QUERY = 'nslice==1'\n",
    "BDT_PRE_QUERY += ' and ' + reco_in_fv_query\n",
    "BDT_PRE_QUERY +=' and contained_fraction>0.9'\n",
    "\n",
    "# signal definition - shower constraints\n",
    "BDT_PRE_QUERY += ' and n_showers_contained==1'\n",
    "BDT_PRE_QUERY += ' and shr_energy_tot_cali>0.07'\n",
    "\n",
    "# signal definition - track constraints\n",
    "BDT_PRE_QUERY += ' and n_tracks_contained>0'\n",
    "BDT_PRE_QUERY += ' and trk_energy>0.04' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDT_LOOSE_CUTS = BDT_PRE_QUERY\n",
    "\n",
    "# loose shower constraints\n",
    "BDT_LOOSE_CUTS +=' and shr_score<0.3'\n",
    "BDT_LOOSE_CUTS += ' and shrmoliereavg<15'\n",
    "BDT_LOOSE_CUTS += ' and shr_tkfit_dedx_Y<7'\n",
    "\n",
    "# loose track constraints\n",
    "BDT_LOOSE_CUTS += ' and trkpid<0.35'\n",
    "BDT_LOOSE_CUTS += ' and tksh_distance<12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = parameters(ISRUN3)['bdt_training_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load bdt model \n",
    "split = 1\n",
    "bdt_model = xgb.Booster({'nthread': 4})\n",
    "bdt_model.load_model(parameters(ISRUN3)['bdt_model'])\n",
    "    \n",
    "datasets_bdt = {}\n",
    "training_parameters = parameters(ISRUN3)['bdt_training_parameters']\n",
    "\n",
    "for i in range(len(datasets)): \n",
    "\n",
    "    df = list(datasets.values())[i].copy()\n",
    "    df = df.query(BDT_LOOSE_CUTS)\n",
    "\n",
    "    # clean datasets \n",
    "    for column in training_parameters:\n",
    "        df.loc[(df[column] < -1.0e37) | (df[column] > 1.0e37), column] = np.nan\n",
    "\n",
    "    # create testing dmatrix \n",
    "    df_test = xgb.DMatrix(data=df[training_parameters])\n",
    "\n",
    "    # apply the bdt selection\n",
    "    preds = bdt_model.predict(df_test)\n",
    "\n",
    "    # add columns for plotting \n",
    "    df['BDT_score'] = preds\n",
    "\n",
    "    datasets_bdt[list(datasets.keys())[i]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_score_cut = parameters(ISRUN3)['bdt_score_cut']\n",
    "    \n",
    "print(\"BDT SCORE THRESHOLD = \"+str(bdt_score_cut))\n",
    "\n",
    "selected_query = BDT_LOOSE_CUTS + ' and BDT_score>'+str(bdt_score_cut)\n",
    "selected_signal_query = selected_query + ' and is_signal==True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GENERATED SIGNAL (DATA NORMALIZED) = \"+str(sum(generated_signal(ISRUN3, 'nu_e', 1, 0, 20))*overlay_scale_to_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT score output \n",
    "\n",
    "x = plot_mc('BDT_score', 20, 0, 1, '', datasets_bdt, ISRUN3, x_label=\"BDT Probability Score\", \n",
    "            norm='data', pot='2$\\\\times10^{20}$', bdt_scale=split, save=False, ymax=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = 'shr_energy_cali'\n",
    "\n",
    "xvar_dict = xsec_variables(xvar, ISRUN3)\n",
    "\n",
    "bins = xvar_dict['bins']\n",
    "true_var = xvar_dict['true_var']\n",
    "x_label = xvar_dict['x_label']\n",
    "beamon_pot = xvar_dict['beamon_pot']\n",
    "xlow = xvar_dict['xlow']\n",
    "xhigh = xvar_dict['xhigh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_mc(xvar, bins, xlow, xhigh, 'BDT_score>'+str(bdt_score_cut), datasets_bdt, ISRUN3, \n",
    "            norm='data', sys=False, x_label='Reco '+x_label, ymax=60, \n",
    "            save=False, save_label=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eff(true_var, bins, xlow, xhigh, 'BDT_score>'+str(bdt_score_cut), datasets_bdt, ISRUN3, \n",
    "         x_label=x_label, ymax=0.4, save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "save_bdt = False\n",
    "\n",
    "training_parameters = parameters(ISRUN3)['bdt_training_parameters']\n",
    "\n",
    "# TRAIN ON A SUBSET OF THE DISTRIBUTION\n",
    "if TRAIN: \n",
    "    BDT_LOOSE_CUTS += ' and -0.9<tksh_angle<0.9'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-determined boosting round numbers\n",
    "if not ISRUN3: \n",
    "    lc_rounds = 200\n",
    "    \n",
    "else: \n",
    "    lc_rounds = 200\n",
    "\n",
    "#test train split \n",
    "split = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN: \n",
    "\n",
    "    # BDT training \n",
    "    bdt_lc = main_BDT(datasets, BDT_LOOSE_CUTS, lc_rounds, training_parameters, ISRUN3, test_size=split)\n",
    "\n",
    "    results_df = bdt_lc['bdt_results_df']\n",
    "    bdt_model = bdt_lc['bdt_model']\n",
    "    train_df = bdt_lc['df_pre_train']\n",
    "    test_df = bdt_lc['df_pre_test']\n",
    "    \n",
    "    # split events into different categories \n",
    "    datasets_bdt = split_events(results_df)\n",
    "\n",
    "# note: all of the plots following be made with half the POT this way (test/train split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_bdt: \n",
    "    bdt_model.save_model('BDT_models/new_bdt.model')\n",
    "    print('saving BDT...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN: \n",
    "\n",
    "    # performance of the linear selection for comparison\n",
    "    gen_num = np.nansum(generated_signal(ISRUN3, xvar, len(bins)-1, bins[0], bins[-1]))*split\n",
    "    eff_box = np.nansum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay'])/gen_num * 100\n",
    "\n",
    "    tot_sel = np.nansum(test_df.query(SEL_QUERY)['weight']) # use weight since EXT does not have totweight_overlay \n",
    "    pur_box = np.nansum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay']) / tot_sel * 100\n",
    "\n",
    "    results_box = [pur_box, eff_box]\n",
    "\n",
    "    #  stat errors on the linear performance \n",
    "    e = eff_box/100\n",
    "\n",
    "    eff_err = math.sqrt( (e*(1-e)) / gen_num ) * 100\n",
    "    pur_err = math.sqrt(np.nansum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay'])) / tot_sel * 100\n",
    "\n",
    "    results_box_err = [pur_err, eff_err]\n",
    "\n",
    "    # x values\n",
    "    x = np.arange(0, 0.8, 0.025)\n",
    "\n",
    "    # returns purity, purErr, eff, effErr\n",
    "    perf_dict = bdt_pe(results_df, x, \n",
    "                  np.array(generated_signal(ISRUN3, xvar, len(bins)-1, bins[0], bins[-1])), split)\n",
    "    pur, pur_err, eff, eff_err = perf_dict['purity'], perf_dict['purErr'], perf_dict['eff'], perf_dict['effErr']\n",
    "    \n",
    "    bdt_box_plot([pur, pur_err, eff, eff_err], x, ISRUN3, save=False, results_box=results_box, results_box_err=results_box_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_svb_plot(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = plot_mc('BDT_score', 20, 0, 1, '', datasets_bdt, ISRUN3, x_label=\"BDT Probability Score\", \n",
    "            norm='data', pot='2$\\\\times10^{20}$', save=False, ymax=30, bdt_scale=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_weight = 'totweight_data'\n",
    "\n",
    "splits = 2\n",
    "repeats = 20\n",
    "cv = RepeatedStratifiedKFold(n_splits=splits, n_repeats=repeats, random_state=36851234)\n",
    "\n",
    "bdt_score_arr = np.arange(0, 0.8, 0.025)\n",
    "\n",
    "q = BDT_LOOSE_CUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossval = addRelevantColumns(datasets)\n",
    "\n",
    "scale_weight = len(df_crossval.query(q + ' and is_signal == False')) / len(df_crossval.query(q + ' and is_signal == True'))\n",
    "print(\"scale pos weight (ratio of negative to positive) = \"+str(scale_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': 'gbtree',\n",
    "        'eta': 0.02,\n",
    "        'tree_method': 'exact',\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 1,\n",
    "        'silent': 1,\n",
    "        'min_child_weight': 1,\n",
    "        'seed': 2002,\n",
    "        'gamma': 1,\n",
    "        'max_delta_step': 0,\n",
    "        'scale_pos_weight': scale_weight,\n",
    "        'eval_metric': ['error', 'auc', 'aucpr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_purity = []\n",
    "final_efficiency=[]\n",
    "\n",
    "fp_err = []\n",
    "fe_err = []\n",
    "\n",
    "box_pur = []\n",
    "box_eff = []\n",
    "\n",
    "boxp_err = []\n",
    "boxe_err = []\n",
    "\n",
    "for train_index, test_index in cv.split(df_crossval, df_crossval['is_signal']):\n",
    "    train, test = df_crossval.iloc[train_index], df_crossval.iloc[test_index]    \n",
    "\n",
    "    bdt_cv_lc = bdt_raw_results(train, test, BDT_LOOSE_CUTS, training_parameters, params, lc_rounds)\n",
    "    \n",
    "    # saves purity, efficiency and respective errors on current test sample for loose cuts BDT\n",
    "    perf = bdt_pe(bdt_cv_lc[0], bdt_score_arr, \n",
    "                  np.array(generated_signal(ISRUN3, xvar, len(bins)-1, bins[0], bins[-1])), split)\n",
    "    pur, pur_err, eff, eff_err = perf['purity'], perf['purErr'], perf['eff'], perf['effErr']\n",
    "    \n",
    "    final_purity.append(pur)\n",
    "    final_efficiency.append(eff)\n",
    "    \n",
    "    fp_err.append(pur_err)\n",
    "    fe_err.append(eff_err)\n",
    "\n",
    "    # saves purity and efficiency and respective errors for linear box cut selection performance on current test sample\n",
    "    sig_sel = sum(test.query(SEL_QUERY+' and is_signal==1')['totweight_overlay'])\n",
    "    tot_sel = sum(test.query(SEL_QUERY)['weight'])\n",
    "    tot_sig = sum(generated_signal(ISRUN3, xvar, len(bins)-1, bins[0], bins[-1]))*split\n",
    "    \n",
    "    p = sig_sel / tot_sel\n",
    "    e = sig_sel / tot_sig\n",
    "    \n",
    "    box_pur.append(p * 100)\n",
    "    box_eff.append(e * 100)\n",
    "    \n",
    "    boxp_err.append(math.sqrt(sig_sel) / tot_sel * 100)\n",
    "    boxe_err.append(math.sqrt((e * (1-e)) / tot_sig) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages results column-wise, which is equivalent to averaging results over the same BDT_score cut\n",
    "\n",
    "results_bdt = [np.mean(final_purity, axis=0), np.mean(fp_err, axis=0), \n",
    "               np.mean(final_efficiency, axis=0), np.mean(fe_err, axis=0)]\n",
    "\n",
    "# linear box cut selection is a normal average over each distinct test sample\n",
    "results_box = [np.mean(box_pur), np.mean(box_eff)]\n",
    "results_box_err = [np.mean(boxp_err), np.mean(boxe_err)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bdt_score_arr)): \n",
    "    if bdt_score_arr[i]>=0.45: \n",
    "        print(\"BDT score > \"+str(round(bdt_score_arr[i], 3)))\n",
    "        print(\"efficiency = \"+str(round(results_bdt[2][i], 1)))\n",
    "        print(\"purity = \"+str(round(results_bdt[0][i], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_box_plot(results_bdt, bdt_score_arr, ISRUN3, results_box=results_box, results_box_err=results_box_err, \n",
    "           save=False, save_label=\"FHC_crossval\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTDATED - Add MC distributions to unfolding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTED MC SIGNAL AS A FUNCTION OF RECO VARIABLE -- SCALES TO DATA\n",
    "\n",
    "#### background subtracted (to emulate the same process as in data)\n",
    "\n",
    "d_reco = plot_mc(xvar, bins, xlow, xhigh, 'BDT_score>'+str(bdt_score_cut), datasets_bdt, ISRUN3, \n",
    "            norm='data', sys=False, x_label='Reco '+x_label, save=False, plot_bkgd=True)\n",
    "\n",
    "bincenters = 0.5*(np.array(bins[1:])+np.array(bins[:-1])) # these will be the entries\n",
    "\n",
    "reco = d_reco['CV'] # signal + background   \n",
    "bkgd = d_reco['background_counts']\n",
    "\n",
    "if xsec_units: \n",
    "    reco_subtracted = [(i-j)/(n_target*flux) for i,j in zip(reco,bkgd)]\n",
    "    print(reco_subtracted)\n",
    "\n",
    "else: \n",
    "    reco_subtracted = [i-j for i,j in zip(reco,bkgd)] # background subtracted distribution - these will be the weights  \n",
    "\n",
    "hreco = TH1D(\"hmeas\", \"Selected MC Signal vs. Reco \"+x_label+\" (\"+xvar+\")\", len(bins)-1, np.array(bins))\n",
    "\n",
    "for i in range(len(bincenters)): \n",
    "    hreco.Fill(bincenters[i], reco_subtracted[i])\n",
    "    print(bincenters[i], reco_subtracted[i])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hreco \n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.hist(bincenters, bins, histtype='bar', range=[xlow, xhigh], color='orange',  \n",
    "         weights=reco_subtracted)\n",
    "\n",
    "plt.xlabel('Reco '+x_label, fontsize=15)\n",
    "#plt.xlim(0, 3)\n",
    "\n",
    "plt.title('Selected MC Signal', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "###########################################################\n",
    "\n",
    "# BACKGROUND SUBTRACTED, MEASURED DISTRIBUTION (DATA!) - TK \n",
    "## hmeas -- replace above with hreco later ##\n",
    "\n",
    "###########################################################\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(top)\n",
    "from top import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATED MC SIGNAL AS A FUNCTION OF TRUE VARIABLE -- SCALES TO DATA\n",
    "\n",
    "htrue_signal_gen = TH1D(\"htrue_signal\", \"Generated MC Signal vs. True \"+x_label+\" (\"+true_var+\")\", len(bins)-1, np.array(bins))\n",
    "\n",
    "bincenters = 0.5*(np.array(bins[1:])+np.array(bins[:-1])) # these will be the entries\n",
    "gen = [x*overlay_scale_to_data for x in generated_signal(ISRUN3, true_var, bins, xlow, xhigh)] # these will be the weights - scales to data \n",
    "\n",
    "for i in range(len(bincenters)): \n",
    "    htrue_signal_gen.Fill(bincenters[i], gen[i])\n",
    "    # print(bincenters[i], gen[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrue_signal_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile.Open(\"/uboone/data/users/kmiller/unfolding/WSVD_\"+xvar+\"_FHCRUN1_MARCH12.root\", \"RECREATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.cd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hreco.Write()\n",
    "htrue_signal_gen.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTDATED - DATA/MC Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add BDT model to data\n",
    "\n",
    "# NOW, apply the model to real data for data/MC comparisons\n",
    "\n",
    "\n",
    "# apply cuts\n",
    "data_bdt = data.copy()\n",
    "data_bdt = data_bdt.query(BDT_LOOSE_CUTS)\n",
    "\n",
    "# clean datasets \n",
    "for column in training_parameters:\n",
    "        data_bdt.loc[(data_bdt[column] < -1.0e37) | (data_bdt[column] > 1.0e37), column] = np.nan\n",
    "    \n",
    "# create testing dmatrix \n",
    "data_test = xgb.DMatrix(data=data_bdt[training_parameters])\n",
    "    \n",
    "# apply the bdt selection\n",
    "preds = bdt_model.predict(data_test)\n",
    "\n",
    "# add columns for plotting \n",
    "data_bdt['BDT_score'] = preds\n",
    "\n",
    "# add to datasets list \n",
    "datasets_bdt.append(data_bdt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUALITY CUTS - out of the box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUALITY CUTS\n",
    "\n",
    "### 'nslice==1'\n",
    "### reco_in_fv_query\n",
    "### contained_fraction>0.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco in FV query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(overlay.query(signal)['contained_fraction'], [round(i*0.1, 1) for i in range(11)],\n",
    "             weights=overlay.query(signal)['totweight_data'])\n",
    "plt.show()\n",
    "\n",
    "h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sf)\n",
    "from selection_functions import plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(overlay.query(signal+' and nu_purity_from_pfp>0.5 and nslice==1 and swtrig_pre==1 and '+in_fv_query)['totweight_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([24373.9, 1658.9, 5283.1, 829.6, 1996.1, 1354.2, 11315.2, 102.4, 312.6, 2825.6, 12669.4, 443.8, 28.7, 320.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contained fraction - made after nslice & reco in FV query \n",
    "\n",
    "x = plot_data('contained_fraction', [round(i*0.1, 1) for i in range(11)], 0, 1, 'nslice==1 and '+reco_in_fv_query, \n",
    "              datasets, \n",
    "              ISRUN3, x_label=\"Contained Fraction\", sys=False, log=True, ymax=1000000000,\n",
    "              y_label='$2 \\\\times 10^{20}$', xtext=0.9, ytext=100000,\n",
    "              save=False, save_label=\"NSLICE_FV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDT_PRE_QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dirt.query(BDT_PRE_QUERY).totweight_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRESELECTION VARIABLES - after quality cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRESELECTION - FOR THE SIGNAL DEFINITION\n",
    "\n",
    "### n_tracks_contained>0'\n",
    "### trk_energy>0.04' # 40 MeV reco pion/proton cut on leading track - what about non-leading tracks?\n",
    "\n",
    "### n_showers_contained==1'\n",
    "### shr_energy_tot_cali>0.07'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_tracks_contained>0'\n",
    "\n",
    "x = plot_data('n_tracks_contained', [i for i in range(8)], 0, 7, '', datasets, \n",
    "              ISRUN3, x_label=\"Contained Tracks\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', xtext=6.7, ytext=7500, ymax=14000, \n",
    "              save=True, save_label=\"QUALCUTS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trk_energy>0.04'\n",
    "\n",
    "x = plot_data('trk_energy', [i*0.2 for i in range(11)], 0, 2, '', datasets, \n",
    "              ISRUN3, x_label=\"Reconstructed Leading Track Energy [GeV]\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', ymax=12000, xtext=1.9, ytext=6900, \n",
    "             save=True, save_label='QUALCUTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_showers_contained==1'\n",
    "\n",
    "x = plot_data('n_showers_contained', [i for i in range(7)], 0, 6, '', datasets, \n",
    "              ISRUN3, x_label=\"Contained Showers\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', xtext=5.7, ytext=9000, ymax=16000, \n",
    "             save=True, save_label='QUALCUTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shr_energy_tot_cali>0.07'\n",
    "\n",
    "x = plot_data('shr_energy_tot_cali', [i*0.01 for i in range(41)], 0, 0.4, '', datasets, \n",
    "              ISRUN3, x_label=\"Total Calibrated Shower Energy [GeV]\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', log=True, xtext=0.38, ytext=450, \n",
    "             save=True, save_label='QUALCUTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOSE CUT VARIABLES - After Preselection Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOSE CUTS - slimming for BDT training \n",
    "\n",
    "### shr_score<0.3'\n",
    "### shrmoliereavg<15'\n",
    "### shr_tkfit_dedx_Y<7'\n",
    "\n",
    "### tksh_distance<12'\n",
    "### trkpid<0.35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sf)\n",
    "from selection_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shr_score\n",
    "\n",
    "x = plot_data('shr_score', [i*0.025 for i in range(21)], 0, 0.5, BDT_PRE_QUERY, datasets, \n",
    "              ISRUN3, x_label=\"Pandora Shower Score\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', xtext=0.48, ytext=375, ymax=650, save=True, save_label='PRESEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrmoliereavg\n",
    "\n",
    "x = plot_data('shrmoliereavg', [i for i in range(31)], 0, 30, \n",
    "              BDT_PRE_QUERY, datasets, \n",
    "              ISRUN3, x_label=\"Average Moliere Shower Angle [$\\\\degree$]\", sys=True, \n",
    "              y_label='$2 \\\\times 10^{20}$', ymax=150, xtext=28, ytext=90, save=True, save_label=\"PRESEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shr_tkfit_dedx_Y\n",
    "\n",
    "x = plot_data('shr_tkfit_dedx_Y', [x*0.5 for x in range(25)], 0, 12, \n",
    "              BDT_PRE_QUERY, datasets, \n",
    "              ISRUN3, x_label=\"dE/dx on the Y plane [MeV/cm]\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=320, xtext=11.5, ytext=170, \n",
    "              save=True, save_label='PRESEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tksh_distance\n",
    "\n",
    "x = plot_data('tksh_distance', [x for x in range(21)], 0, 20, \n",
    "              BDT_PRE_QUERY, datasets, \n",
    "              ISRUN3, x_label=\"Distance between track & shower [cm]\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=250, xtext=19, ytext=140, \n",
    "             save=True, save_label='PRESEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trkpid \n",
    "\n",
    "x = plot_data('trkpid', [-1, -0.9, -0.8, -.7, -.6, -.5, -.4, -.3, -.2, -.1, 0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1], -1, 1, \n",
    "              BDT_PRE_QUERY, datasets, \n",
    "              ISRUN3, x_label=\"Track PID Score\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=500, xtext=0.8, ytext=275, \n",
    "              save=True, save_label=\"PRESEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPENING ANGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data('tksh_angle', [-1, -0.9, -0.8, -.7, -.6, -.5, -.4, -.3, -.2, -.1, 0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1], -1, 1, \n",
    "              BDT_LOOSE_CUTS, datasets, \n",
    "              ISRUN3, x_label=\"Reco $cos \\\\theta_{ep}$\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=50, xtext=0.85, ytext=28, \n",
    "              save=True, save_label=\"LOOSE_CUTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BDT TRAINING VARIABLES - After Preselection & Loose Cuts & Opening Angle cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tksh_angle\n",
    "\n",
    "# BDT TRAINING VARIABLES \n",
    "\n",
    "### shr score (already shown )\n",
    "### shrmoliereavg (already shown)\n",
    "### shr_tkfit_dedx_Y (already shown)\n",
    "### subcluster\n",
    "\n",
    "### trkpid (already shown)\n",
    "### tksh_distance (already shown)\n",
    "### trkshrhitdist2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shr score (already shown )\n",
    "#x = plot_data('shr_score', [0, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275,0.3], 0, 0.3, \n",
    "#              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "#              ISRUN3, x_label=\"Pandora Shower Score\", sys=False, \n",
    "#              y_label='$2 \\\\times 10^{20}$', xtext=0.29, ytext=90, ymax=160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shrmoliereavg (already shown)\n",
    "#x = plot_data('shrmoliereavg', [i for i in range(16)], 0, 15, \n",
    "#              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "#              ISRUN3, x_label=\"Average Moliere Shower Angle [$\\\\degree$]\", sys=False, \n",
    "#              y_label='$2 \\\\times 10^{20}$', ymax=60, xtext=14.5, ytext=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shr_tkfit_dedx_Y (already shown)\n",
    "#x = plot_data('shr_tkfit_dedx_Y', [x*0.5 for x in range(15)], 0, 7, \n",
    "#              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "#              ISRUN3, x_label=\"dE/dx on the Y plane [MeV/cm]\", \n",
    "#              sys=False, y_label='$2 \\\\times 10^{20}$', ymax=100, xtext=6.7, ytext=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data('subcluster', [5*x for x in range(11)], 0, 50, \n",
    "              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "              ISRUN3, x_label=\"Number of Shower Subclusters\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=130, xtext=47, ytext=75, save=True, save_label='LOOSE_CUTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = plot_data('trkpid', 10, 0, 1, \n",
    "#              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "#              ISRUN3, x_label=\"Track PID Score\", \n",
    "#              sys=False, y_label='$2 \\\\times 10^{20}$', ymax=50, xtext=0.34, ytext=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data('trkshrhitdist2', [x for x in range(9)], 0, 8, \n",
    "              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "              ISRUN3, x_label=\"2D Distance Between track & shower [cm]\", \n",
    "              sys=True, y_label='$2 \\\\times 10^{20}$', ymax=190, xtext=7.5, ytext=110, save=True, save_label='LOOSE_CUTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### already shown \n",
    "#x = plot_data('tksh_distance', [x for x in range(13)], 0, 12, \n",
    "#              BDT_LOOSE_CUTS+' and -0.9<tksh_angle<0.9', datasets, \n",
    "#              ISRUN3, x_label=\"Distance between track & shower [cm]\", \n",
    "#              sys=False, y_label='$2 \\\\times 10^{20}$', ymax=120, xtext=11.5, ytext=68, \n",
    "#             save=False, save_label='LOOSE_CUTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT SCORE OUTPUT\n",
    "\n",
    "x = plot_data('BDT_score', [round(i*0.1,1) for i in range(10)], 0, 0.9, '', datasets_bdt, ISRUN3,\n",
    "          x_label=\"BDT Probability Score\", sys=False, ymax=105, xtext=0.84, ytext=60, y_label='$2 \\\\times 10^{20}$', save=True, \n",
    "             save_label='BDT_SCORE_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data(xvar, bins, bins[0], bins[-1], 'BDT_score>'+str(bdt_score_cut), datasets_bdt, ISRUN3,\n",
    "          x_label='Reco '+x_label, sys=True, y_label='$2 \\\\times 10^{20}$', ymax=60, save=True, save_label='BDTcut_MCONLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0.09, 0.4, 0.65, 1, 3]\n",
    "fine_bins = [0.09, .2, .3, .4, .5, .65, .75, .85, 1.0, 1.5, 2, 2.5, 3]\n",
    "xvar = \"shr_energy_cali\"\n",
    "true_var = \"elec_e\"\n",
    "x_label = \"Electron Energy [GeV]\" #\"Shower Energy [GeV]\"\n",
    "data_pot = \"$2.0\\\\times10^{20}$ POT\"\n",
    "xlow = 0.09\n",
    "xhigh = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDT_LOOSE_CUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(uncertainty_functions)\n",
    "from uncertainty_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sf)\n",
    "from selection_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgdonly=calcSysError('BDT_score', [round(i*0.1,1) for i in range(10)], 0, 0.9, BDT_LOOSE_CUTS, \n",
    "                                       datasets_bdt, 'weightsGenie', 600, ISRUN3, plot=True, background_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA / MC -- after preselection cuts \n",
    "# slice purity, nslice, reco FV, containment, total shower energy \n",
    "\n",
    "q = ''\n",
    "\n",
    "x = plot_data('reco_nu_vtx_sce_x', 30, 0, 250, q,  datasets, ISRUN3, ymax=350,\n",
    "          x_label=\"Reconstructed Interaction Vertex (X) [cm]\", xtext=240, ytext=200, sys=False)\n",
    "\n",
    "x = plot_data('reco_nu_vtx_sce_y', 30, -110, 110, q,  datasets, ISRUN3, ymax=325,\n",
    "          x_label=\"Reconstructed Interaction Vertex (Y) [cm]\", xtext=-40, ytext=185, sys=False)\n",
    "\n",
    "x = plot_data('reco_nu_vtx_sce_z', 30, 0, 1000, q,  datasets, ISRUN3, ymax=325,\n",
    "          x_label=\"Reconstructed Interaction Vertex (z) [cm]\", xtext=300, ytext=195, sys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data('n_showers_contained', 5, 0, 5, q, datasets, ISRUN3, x_label=\"Number of Showers\", ymax=4000, \n",
    "         xtext=4.8, ytext=2250, sys=False)\n",
    "\n",
    "x = plot_data('n_tracks_contained', 7, 0, 7, q, datasets, ISRUN3, x_label='Number of Tracks', ymax=2500, \n",
    "         xtext=6.5, ytext=1450, sys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_data('shr_energy_tot_cali', 5, 0, 5, q, datasets, ISRUN3, x_label='Total Calibrated Shower Energy [GeV]', ymax=6000, sys=False) \n",
    "x = plot_data('trkpid', 20, -1, 1, q, datasets, ISRUN3, x_label='Track PID Score', sys=False) \n",
    "x = plot_data('shr_score', 15, 0, .5, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score', sys=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT preselection \n",
    "\n",
    "#shower score \n",
    "#trk PID\n",
    "#shrmoliereavg \n",
    "#shr_tkfit_dedx_Y\n",
    "#tksh_distance\n",
    "\n",
    "q = BDT_PRE_QUERY\n",
    "\n",
    "x = plot_data('shr_score', 10, 0, .5, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score', ymax=1200, sys=False) \n",
    "x = plot_data('trkpid', 10, -1, 1, q, datasets, ISRUN3, x_label='Track PID Score', ymax=800) \n",
    "x = plot_data('shrmoliereavg', 8, 0, 40, q, datasets, ISRUN3, x_label='Avg Shower Moliere Angle [degrees]', ymax=700)\n",
    "x = plot_data('shr_tkfit_dedx_Y', 10, 0, 10, q, datasets, ISRUN3, x_label='dE/dx on the Collection Plane [MeV/cm]', ymax=500) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT Loose cuts\n",
    "\n",
    "#shr_score\n",
    "#shrmoliereavg \n",
    "#trk pid\n",
    "#n_showers_contained\n",
    "#subcluster\n",
    "#trkshrhitdist2\n",
    "\n",
    "q = BDT_LOOSE_CUTS\n",
    "\n",
    "x = plot_data('BDT_score', [x/10 for x in range(10)], 0, 0.9, q, datasets_bdt, ISRUN3, \n",
    "          norm='pot', ymax=110, x_label='BDT Score', sys=False) \n",
    "\n",
    "x = plot_data('shr_score', 10, 0, .3, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score', ymax=300) \n",
    "x = plot_data('shrmoliereavg', 5, 0, 15, q, datasets, ISRUN3, x_label='Avg Shower Moliere Angle [degrees]', ymax=175)\n",
    "x = plot_data('trkpid', 10, -1, .35, q, datasets, ISRUN3, x_label='Track PID Score', ymax=130) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query here?\n",
    "\n",
    "x = plot_data('BDT_score', [x/10 for x in range(10)], 0, 0.9, '', datasets_bdt, ISRUN3, \n",
    "          norm='pot', ymax=110, x_label='BDT Score', sys=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT cut - xsec variables\n",
    "\n",
    "x = plot_data('n_tracks_contained', [1,2,3,7], 1, 7, 'BDT_score>0.55', datasets_bdt, ISRUN3, norm='pot', ymax=100, \n",
    "         save=False, save_label='fhc_data_BDT', sys=False, x_label=\"Contained Tracks\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
