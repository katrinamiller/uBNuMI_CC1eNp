{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear vs. BDT selection performance with data/MC comparisons\n",
    "# make sure to update the plots_path here & in backend function scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import selection_functions as sf\n",
    "\n",
    "import importlib\n",
    "\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NuMIGeoWeights\n",
    "importlib.reload(NuMIGeoWeights)\n",
    "\n",
    "# the default option is FHC, RHC needs different arguments\n",
    "numiBeamlineGeoWeights = NuMIGeoWeights.NuMIGeoWeights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sf)\n",
    "from selection_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3??\n",
    "ISRUN3 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nue intrinsic? \n",
    "NUE_INTRINSIC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISRUN3: \n",
    "    plots_path = \"/uboone/data/users/kmiller/searchingfornues_v33/v08_00_00_33/plots/rhc/\"\n",
    "\n",
    "else: \n",
    "    plots_path = \"/uboone/data/users/kmiller/searchingfornues_v33/v08_00_00_33/plots/fhc/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POT normalization factors\n",
    "\n",
    "# FHC\n",
    "if not ISRUN3:  \n",
    "    overlay_pot =  2.33652E21  # v7       \n",
    "    dirt_pot = 1.67392E21 # david's file\n",
    "    beamon_pot = 2.0E20 # v5\n",
    "\n",
    "    beamon_ntrig =  5268051.0 # v5 (EA9CNT_wcut)\n",
    "    beamoff_ntrig = 9199232.74  # v5 (EXT_NUMIwin_FEMBeamTriggerAlgo)\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        nue_intrinsic_pot = 2.37838E22 # v7\n",
    "    \n",
    "\n",
    "# RHC \n",
    "else: \n",
    "    overlay_pot =  1.98937E21 # v7\n",
    "    dirt_pot = 4.65831E20 # v3\n",
    "    beamon_pot = 5.0E20 # v5\n",
    "    \n",
    "    beamon_ntrig = 10363728.0 # v5\n",
    "    beamoff_ntrig =  32878305.25 # v5\n",
    "        \n",
    "    if NUE_INTRINSIC: \n",
    "        nue_intrinsic_pot = 2.5345E22 # v7\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "DATA = \"\"\n",
    "EXT = \"\"\n",
    "OVRLY  = \"\"\n",
    "DRT = \"\"\n",
    "NUE = \"\"\n",
    "\n",
    "#path = '/uboone/data/users/kmistry/work/MCC9/searchingfornues/'\n",
    "\n",
    "#reduced\n",
    "#path = '/uboone/app/users/kmiller/searchingfornues_v33/Jan2021_NuMI_workshopDay2/Day1/root_files/'\n",
    "\n",
    "# reduced with opening angle \n",
    "path = '/uboone/data/users/kmiller/ntuples/run1/nuepresel/'\n",
    "\n",
    "if not ISRUN3: \n",
    "    \n",
    "    # Run 1 FHC \n",
    "    OVRLY = 'neutrinoselection_filt_run1_overlay_v7'\n",
    "    EXT = 'neutrinoselection_filt_run1_beamoff_v5'\n",
    "    DATA = 'neutrinoselection_filt_run1_beamon_beamgood_v5'\n",
    "    DRT = 'prodgenie_numi_uboone_overlay_dirt_fhc_mcc9_run1_v28_all_snapshot'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'neutrinoselection_filt_run1_overlay_intrinsic_v7'\n",
    "\n",
    "else: \n",
    "    # Run 3 RHC\n",
    "    OVRLY = 'ntuple_files_v7/neutrinoselection_filt_run3b_overlay'\n",
    "    DATA = 'ntuple_files_v5/neutrinoselection_filt_run3b_beamon_beamgood'\n",
    "    EXT = 'ntuple_files_v5/neutrinoselection_filt_run3b_beamoff'\n",
    "    DRT = 'ntuple_files_v3/neutrinoselection_filt_run3b_dirt_overlay'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'ntuple_files_v7/neutrinoselection_filt_run3b_overlay_intrinsic'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = uproot.open(path+OVRLY+\".root\")[fold][tree]\n",
    "data = uproot.open(path+DATA+\".root\")[fold][tree]\n",
    "ext = uproot.open(path+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(path+DRT+\".root\")[fold][tree]  \n",
    "\n",
    "uproot_v = [overlay,data,ext,dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue = uproot.open(path+NUE+\".root\")[fold][tree]\n",
    "    uproot_v.append(nue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"selected\", \"nu_pdg\", \"shr_theta\", \"true_e_visible\", \n",
    "    \"trk_score_v\", \n",
    "    \"shr_tkfit_dedx_Y\", \"ccnc\", \"n_tracks_contained\", \n",
    "    \"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trkshrhitdist2\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"nu_purity_from_pfp\", \n",
    "    \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_score\", \n",
    "    \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\n",
    "    \"shr_energy_tot_cali\",  \n",
    "    \"nslice\", \n",
    "    \"contained_fraction\",\n",
    "    \"true_nu_vtx_x\", \"true_nu_vtx_y\" , \"true_nu_vtx_z\", \n",
    "    \"npion\", \"shr_energy_cali\", \n",
    "    \"shrmoliereavg\", \"shr_px\", \"shr_py\", \"shr_pz\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MC only variables\n",
    "mc_var = [\"weightSplineTimesTune\", \"true_nu_px\", \"true_nu_py\", \"true_nu_pz\", \n",
    "            \"elec_e\", \"proton_e\", \"mc_px\", \"mc_py\", \"mc_pz\", \"elec_px\", \"elec_py\", \"elec_pz\", \n",
    "            \"swtrig_pre\", \"ppfx_cv\", \"mc_pdg\", \"opening_angle\"]\n",
    "\n",
    "sys_genie = [\"weightsGenie\", \"weightsReint\"]\n",
    "sys_flux = ['weightsPPFX']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = overlay.pandas.df(variables + mc_var + sys_genie + sys_flux, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay['weightsPPFX'] = overlay['weightsPPFX']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt = dirt.pandas.df(variables + mc_var + sys_genie, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no flux weights exist for dirt (yet?)\n",
    "dirt['weightsPPFX'] = [[1 for x in range(len(overlay['weightsPPFX'].iloc[0]))] for y in range(len(dirt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUE_INTRINSIC: \n",
    "    nue = nue.pandas.df(variables + mc_var + sys_genie + sys_flux, flatten=False)\n",
    "    nue['weightsPPFX'] = nue['weightsPPFX']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.pandas.df(variables, flatten=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ext.pandas.df(variables, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all datasets have all the variables\n",
    "# but we want them to be of equal # of columns (and in order, annoyingly)\n",
    "\n",
    "for var in mc_var+sys_genie+sys_flux: \n",
    "    data[var] = np.nan\n",
    "    ext[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" \n",
    "# (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "#LLR-PID : log likelihood ratio particle ID \n",
    "\n",
    "df_v = [overlay,data,ext,dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    df_v.append(nue)\n",
    "    \n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    #df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    df['NeutrinoEnergy2_GeV'] = df['NeutrinoEnergy2']/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add truth level theta & phi angles (detector & beam coordinates)\n",
    "overlay = addAngles(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt = addAngles(dirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUE_INTRINSIC: \n",
    "    nue = addAngles(nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = [overlay, dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    mc_df.append(nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add beamline geometry weights \n",
    "\n",
    "for i,df in enumerate(mc_df):\n",
    "    df['weightsNuMIGeo'] = df.apply( lambda x: numiBeamlineGeoWeights.calculateGeoWeight(x['nu_pdg'],x['nu_e'],x['thbeam']) , axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all datasets have all the variables, but we want them to be of equal # of columns\n",
    "\n",
    "nan_var = ['thdet', 'phidet', 'true_nu_px_beam', 'true_nu_py_beam', 'true_nu_pz_beam', 'thbeam', 'phibeam','weightsNuMIGeo']\n",
    "\n",
    "for var in nan_var: \n",
    "    data[var] = np.nan\n",
    "    ext[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.setdiff1d(ext.columns,overlay.columns)\n",
    "#ext.columns == overlay.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts applied for bad GENIE weights \n",
    "for i,df in enumerate(mc_df):\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pot scaling weights \n",
    "\n",
    "# applied tunes \n",
    "dirt_tune = 1\n",
    "ext_tune = 1\n",
    "\n",
    "if not ISRUN3: \n",
    "    dirt_tune = 0.35\n",
    "    ext_tune = .98\n",
    "    \n",
    "else: \n",
    "    dirt_tune = 0.35\n",
    "    ext_tune = .94\n",
    "    \n",
    "    \n",
    "##############################################\n",
    "# SCALE  TO BEAM ON POT\n",
    "overlay_scale = beamon_pot/overlay_pot\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue_scale = beamon_pot/nue_intrinsic_pot\n",
    "\n",
    "dirt_scale = dirt_tune*(beamon_pot/dirt_pot)\n",
    "beamoff_scale = ext_tune*(beamon_ntrig/beamoff_ntrig) # scale factor to beam on POT\n",
    "\n",
    "overlay['pot_scale'] = overlay_scale \n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['pot_scale'] = nue_scale\n",
    "    \n",
    "dirt['pot_scale'] = dirt_scale\n",
    "ext['pot_scale'] = beamoff_scale\n",
    "data['pot_scale'] = [1 for x in range(len(data))]\n",
    "##############################################\n",
    "# SCALE TO OVERLAY\n",
    "\n",
    "dirt_scale2 = dirt_tune*(overlay_pot/dirt_pot)\n",
    "beamoff_scale2 = ext_tune*((overlay_pot/beamon_pot)*(beamon_ntrig/beamoff_ntrig))\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue_scale2 = overlay_pot/nue_intrinsic_pot\n",
    "\n",
    "overlay['pot_scale_overlay'] = [1 for x in range(len(overlay))]\n",
    "if NUE_INTRINSIC: \n",
    "    nue['pot_scale_overlay'] = nue_scale2\n",
    "    \n",
    "dirt['pot_scale_overlay'] = dirt_scale2\n",
    "ext['pot_scale_overlay'] = beamoff_scale2\n",
    "data['pot_scale_overlay'] = [1 for x in range(len(data))]\n",
    "##############################################\n",
    "# SCALE TO PROJECTED \n",
    "proj_pot = 0.0\n",
    "\n",
    "if not ISRUN3: \n",
    "    proj_pot = 9.23E20 # FHC\n",
    "else: \n",
    "    proj_pot = 11.95E20 # RHC\n",
    "\n",
    "overlay_scale3 = proj_pot/overlay_pot\n",
    "dirt_scale3 = dirt_tune*(proj_pot/dirt_pot)\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue_scale3 = proj_pot/nue_intrinsic_pot\n",
    "\n",
    "# first scale to beamon, then scale to projected\n",
    "beamoff_scale3 = (ext_tune*(beamon_ntrig/beamoff_ntrig)) * (proj_pot/beamon_pot)\n",
    "\n",
    "overlay['pot_scale_proj'] = overlay_scale3\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['pot_scale_proj'] = nue_scale3\n",
    "    \n",
    "dirt['pot_scale_proj'] = dirt_scale3\n",
    "ext['pot_scale_proj'] = beamoff_scale3\n",
    "data['pot_scale_proj'] = [1 for x in range(len(data))]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total weights \n",
    "\n",
    "# combined genie * POT weight * flux weight \n",
    "# ext gets POT weight only \n",
    "\n",
    "flux_weight = 'ppfx_cv'\n",
    "\n",
    "################################################################\n",
    "# totweight scales to BEAMON\n",
    "\n",
    "# tuned\n",
    "overlay['totweight'] = overlay['pot_scale']*overlay[flux_weight]*overlay['weightSplineTimesTune']\n",
    "dirt['totweight'] = dirt['pot_scale']*dirt[flux_weight]*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['totweight'] = nue['pot_scale']*nue[flux_weight]*nue['weightSplineTimesTune']\n",
    "\n",
    "\n",
    "################################################################\n",
    "# totweight_overlay scales to STANDARD OVERLAY\n",
    "\n",
    "# tuned\n",
    "overlay['totweight_overlay'] = overlay[flux_weight]*overlay['weightSplineTimesTune']\n",
    "dirt['totweight_overlay'] = dirt['pot_scale_overlay']*dirt[flux_weight]*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC:\n",
    "    nue['totweight_overlay'] = nue['pot_scale_overlay']*nue[flux_weight]*nue['weightSplineTimesTune']\n",
    "\n",
    "################################################################\n",
    "# totweight_proj scales to TOTAL PROJECTED BEAM ON \n",
    "\n",
    "overlay['totweight_proj'] = overlay['pot_scale_proj']*overlay[flux_weight]*overlay['weightSplineTimesTune']\n",
    "dirt['totweight_proj'] = dirt['pot_scale_proj']*dirt[flux_weight]*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC:\n",
    "    nue['totweight_proj'] = nue['pot_scale_proj']*nue[flux_weight]*nue['weightSplineTimesTune']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add offline flux weights? \n",
    "if offlineFluxWeights: \n",
    "    mc_df = offline_flux_weights(mc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the number of columns the same \n",
    "new_var = ['totweight', 'totweight_overlay', 'totweight_proj']\n",
    "\n",
    "if offlineFluxWeights: \n",
    "    new_var.append('weightFlux')\n",
    "\n",
    "for var in new_var: \n",
    "    for df in [data, ext]: \n",
    "        df[var] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare intrinsic with standard overlay events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fv_query = \"10<=true_nu_vtx_x<=246 and -106<=true_nu_vtx_y<=106 and 10<=true_nu_vtx_z<=1026\"\n",
    "reco_in_fv_query = \"10<=reco_nu_vtx_sce_x<=246 and -106<=reco_nu_vtx_sce_y<=106 and 10<=reco_nu_vtx_sce_z<=1026\"\n",
    "\n",
    "nueCC_query = 'abs(nu_pdg)==12 and ccnc==0 and '+in_fv_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueCC_overlay = overlay.query(nueCC_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply FV cut to intrinsic (already applied to overlay)\n",
    "nue_fv = nue.query(in_fv_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nueCC_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nue_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with latest genie tune \n",
    "\n",
    "weight = 'totweight_overlay'\n",
    "\n",
    "# stat error bars on standard overlay \n",
    "n, b, p = plt.hist(nueCC_overlay.query(SEL_QUERY)['nu_e'], 25, range=[0, 5], \n",
    "                   weights=nueCC_overlay.query(SEL_QUERY)[weight])\n",
    "plt.close()\n",
    "\n",
    "bincenters = 0.5*(b[1:]+b[:-1])\n",
    "overlay_err =  np.sqrt(n)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.hist(nue_fv.query(SEL_QUERY)['nu_e'], 25, range=[0, 5], \n",
    "         weights=nue_fv.query(SEL_QUERY)[weight], alpha=0.7, label='nue intrinsic')\n",
    "\n",
    "plt.hist(nueCC_overlay.query(SEL_QUERY)['nu_e'], 25, range=[0, 5], \n",
    "         weights=nueCC_overlay.query(SEL_QUERY)[weight], alpha=0.7, \n",
    "         label='standard overlay')\n",
    "\n",
    "plt.errorbar(bincenters, n, yerr=overlay_err, fmt='none', color='black', linewidth=1)\n",
    "\n",
    "plt.xlabel('true neutrino energy [GeV]', fontsize=15)\n",
    "plt.ylabel('events (normalized to 2.3E21 POT)', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "#plt.ylim(0, 1300)\n",
    "plt.title('selected nue/nuebar CC events, unweighted', fontsize=15)\n",
    "plt.grid()\n",
    "#plt.savefig('/uboone/data/users/kmiller/searchingfornues_v33/v08_00_00_33/plots/fhc/intrinsic_compare_weighted_selected.pdf', \n",
    "#           transparent=True, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUE_INTRINSIC: \n",
    "    # intrinsic sample contains in AV TPC events ONLY, & only CC events (overlay is entire cryo)\n",
    "    in_AV_query = \"-1.55<=true_nu_vtx_x<=254.8 and -116.5<=true_nu_vtx_y<=116.5 and 0<=true_nu_vtx_z<=1036.8\"\n",
    "    \n",
    "    # remove the nue/nuebar CC in overlay\n",
    "    nueCC_query = 'abs(nu_pdg)==12 and ccnc==0 and '+in_AV_query\n",
    "    print(\"# of nueCC in AV in overlay sample = \"+str(len(overlay.query(nueCC_query))))\n",
    "    len1 = len(overlay)\n",
    "    \n",
    "    idx = overlay.query(nueCC_query).index\n",
    "    overlay.drop(idx, inplace=True)\n",
    "    len2 = len(overlay) \n",
    "    print(\"# of nueCC in AV dropped in overlay = \"+str(len1-len2))\n",
    "    \n",
    "    # then add in nue_intrinsic \n",
    "    overlay = pd.concat([overlay,nue], ignore_index=True)\n",
    "\n",
    "    # from here on out everything else should be the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SW trigger, combine overlay + dirt as MC \n",
    "mc = pd.concat([overlay.query('swtrig_pre==1'),dirt.query('swtrig_pre==1')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate by in/out FV & cosmic\n",
    "\n",
    "infv = mc.query(in_fv_query+' and nu_purity_from_pfp>0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic = mc.query(in_fv_query+' and nu_purity_from_pfp<=0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfv = mc.query(out_fv_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check that everything is accounted for \n",
    "print(len(mc)==len(infv)+len(cosmic)+len(outfv))\n",
    "\n",
    "if not (len(mc)==len(infv)+len(cosmic)+len(outfv)): \n",
    "    d = len(mc) - (len(infv)+len(cosmic)+len(outfv))\n",
    "    print(d)\n",
    "    \n",
    "     \n",
    "    m = pd.concat([infv, cosmic, outfv])\n",
    "    diff = np.setdiff1d(list(mc.index),list(m.index))\n",
    "\n",
    "    #for i in range(d):\n",
    "        #print(mc.loc[diff[i], 'nu_purity_from_pfp'])\n",
    "        #print(mc.loc[diff[i], 'nslice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many signal events do we start with in FV -- normalized to overlay ? \n",
    "\n",
    "tot_signal_weighted = np.nansum(mc.query(signal+' and '+in_fv_query)['totweight_overlay'])\n",
    "print(tot_signal_weighted)\n",
    "\n",
    "# how many signal events are not cosmic cont?\n",
    "tot_signal_weighted2 = np.nansum(mc.query('nu_purity_from_pfp>0.5'+' and '+signal+' and '+in_fv_query)['totweight_overlay'])\n",
    "print(tot_signal_weighted2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 main categories: \n",
    "\n",
    "# infv - overlay & dirt events with truth vtx in FV \n",
    "# outfv - overlay & dirt events with truth vtx in FV that are classified as neutrinos\n",
    "# cosmic - overlay & dirt events with true vtx in FV that get misclassified as cosmic \n",
    "# ext - beam OFF data\n",
    "# data - beam ON data \n",
    "\n",
    "datasets = [infv, outfv, cosmic, ext, data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preselection \n",
    "PRE_QUERY = 'nslice==1' # \n",
    "PRE_QUERY += ' and ' + reco_in_fv_query \n",
    "PRE_QUERY +=' and contained_fraction>0.9' \n",
    "\n",
    "PRE_QUERY += ' and n_showers_contained>0'\n",
    "PRE_QUERY += ' and n_tracks_contained>0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new optimized selection by Kaushal \n",
    "SEL_QUERY = PRE_QUERY\n",
    "SEL_QUERY += ' and shr_energy_tot_cali>0.07' #\n",
    "\n",
    "SEL_QUERY += ' and shr_score<0.125'\n",
    "SEL_QUERY += ' and shrmoliereavg < 8'\n",
    "SEL_QUERY += ' and trkpid<0'\n",
    "\n",
    "SEL_QUERY += ' and n_showers_contained == 1'\n",
    "SEL_QUERY += ' and shr_tkfit_dedx_Y<4'\n",
    "\n",
    "\n",
    "if not ISRUN3: \n",
    "    SEL_QUERY += ' and tksh_distance<5'\n",
    "    SEL_QUERY += ' and -0.9<tksh_angle<0.8'\n",
    "\n",
    "else: \n",
    "    SEL_QUERY += ' and tksh_distance<4'\n",
    "    SEL_QUERY += ' and -0.8<tksh_angle<0.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data/MC comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA / MC -- after nslice cut \n",
    "\n",
    "q = 'nslice==1'\n",
    "\n",
    "plot_data('reco_nu_vtx_sce_x', 30, 0, 250, q,  datasets, ISRUN3, #ymax=25000,\n",
    "          x_label=\"Reconstructed Interaction Vertex (X) [cm]\")\n",
    "plot_data('reco_nu_vtx_sce_y', 30, 0, 120, q,  datasets, ISRUN3, #ymax=20000,\n",
    "          x_label=\"Reconstructed Interaction Vertex (Y) [cm]\")\n",
    "plot_data('reco_nu_vtx_sce_z', 30, 0, 1040, q,  datasets, ISRUN3, #ymax=17500,\n",
    "          x_label=\"Reconstructed Interaction Vertex (z) [cm]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after nslice & containment cuts\n",
    "q += ' and '+reco_in_fv_query+ ' and contained_fraction>0.9'\n",
    "\n",
    "plot_data('n_showers_contained', 5, 0, 5, q, datasets, ISRUN3, x_label=\"Number of Showers\", ymax=15000)\n",
    "plot_data('n_tracks_contained', 7, 0, 7, q, datasets, ISRUN3, x_label='Number of Tracks', ymax=15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after preselection \n",
    "\n",
    "q = PRE_QUERY\n",
    "\n",
    "plot_data('shr_energy_tot_cali', 10, 0, 0.25, q, datasets, ISRUN3, \n",
    "          x_label='Total Calibrated Shower Energy [GeV]', ymax=2000) \n",
    "\n",
    "plot_data('CosmicIP', 10, 0, 50, q, datasets, ISRUN3, x_label='Distance to Closest Cosmic [cm]', ymax=500)\n",
    "plot_data('hits_ratio', 20, 0, 1, q, datasets, ISRUN3, x_label='Shower Hits / Total Hits', ymax=800) \n",
    "plot_data('trkpid', 20, -1, 1, q, datasets, ISRUN3, x_label='Track PID Score') \n",
    "plot_data('shr_score', 15, 0, .5, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tksh_angle\n",
    "q = PRE_QUERY\n",
    "\n",
    "plot_data('tksh_angle', 20, -1, 1, q, datasets, ISRUN3, x_label='cos($\\\\theta$)', ymax=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after preselection + numu cuts\n",
    "\n",
    "q = PRE_QUERY+' and shrmoliereavg<8 and trkpid<0 and shr_score<0.125'\n",
    "\n",
    "p = plot_mc('shr_tkfit_dedx_Y', 20, 0, 6, q, datasets, ISRUN3, plt_norm='data', \n",
    "         x_label='dE/dx on the Collection Plane [MeV/cm]', ymax=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projected event distribution \n",
    "\n",
    "plot_mc('nu_e', 16, 0, 4, SEL_QUERY, datasets, ISRUN3, plt_norm='proj', pot='', ymax=110,\n",
    "            x_label=\"True Neutrino Energy [GeV]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cuts for selection performance plot \n",
    "\n",
    "cuts = ['nslice==1',  \n",
    "        reco_in_fv_query, \n",
    "        'contained_fraction>0.9', \n",
    "        'n_tracks_contained>0', \n",
    "        'shr_energy_tot_cali>0.07', \n",
    "        'shr_score<0.125', \n",
    "        'shrmoliereavg<8', \n",
    "        'trkpid<0', \n",
    "        'n_showers_contained==1', \n",
    "        'shr_tkfit_dedx_Y<4']\n",
    "\n",
    "if not ISRUN3: \n",
    "    cuts.append('tksh_distance<5')\n",
    "    cuts.append('-0.9<tksh_angle<0.8')\n",
    "\n",
    "else: \n",
    "    cuts.append('tksh_distance<4')\n",
    "    cuts.append('-0.8<tksh_angle<0.8')\n",
    "    \n",
    "    \n",
    "cut_names = ['Slice ID', \"Reco'd in FV\", 'Containment', \"# Tracks\", \"Tot. Shr Energy\", \n",
    "             'Shr Score', 'Shr Moliere Angle', 'Trk PID', '# Shrs', 'dE/dx (Y plane)', \n",
    "             'Trk/Shr Distance', 'Trk/Shr Angle']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = sel_perf(cuts, datasets, 'totweight_overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eff('nu_e', 16, 0, 4, SEL_QUERY, datasets, ISRUN3, x_label='True Neutrino Energy [GeV]', ymax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purity & efficiency as a function of cut \n",
    "\n",
    "pur_cut = perf['purity (%)']*.01\n",
    "eff_cut = perf['efficiency (%)']*.01\n",
    "rel_eff_cut = perf['rel. eff. (%)']*.01\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(list(range(len(pur_cut))), pur_cut, '-o', color='firebrick', \n",
    "         label='Purity', markersize=3, linewidth=2)\n",
    "plt.plot(list(range(len(pur_cut))), eff_cut, '-o', color='seagreen', \n",
    "         label='Efficiency', markersize=3, linewidth=2)\n",
    "plt.plot(list(range(len(pur_cut))), rel_eff_cut, '-o', color='goldenrod', \n",
    "         label='Relative Efficiency', markersize=3, linewidth=2)\n",
    "\n",
    "plt.grid(linestyle=\":\")\n",
    "\n",
    "plt.xticks(list(range(12)), cut_names, ha='right', fontsize=12)\n",
    "plt.xticks(rotation=40)\n",
    "plt.yticks([0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1],  fontsize=12)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.32, 0.37), fontsize=15)\n",
    "\n",
    "plt.title(\"Selection Performance\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDT_PRE_QUERY = 'nslice==1'\n",
    "BDT_PRE_QUERY += ' and ' + reco_in_fv_query\n",
    "BDT_PRE_QUERY +=' and contained_fraction>0.9'\n",
    "BDT_PRE_QUERY += ' and n_tracks_contained>0'\n",
    "BDT_PRE_QUERY += ' and n_showers_contained==1'\n",
    "BDT_PRE_QUERY += ' and shr_energy_tot_cali>0.07'\n",
    "\n",
    "BDT_LOOSE_CUTS = BDT_PRE_QUERY\n",
    "BDT_LOOSE_CUTS += ' and shr_score<0.3'\n",
    "BDT_LOOSE_CUTS += ' and trkpid<0.35'\n",
    "BDT_LOOSE_CUTS += ' and shrmoliereavg<15'\n",
    "BDT_LOOSE_CUTS += ' and shr_tkfit_dedx_Y<7'\n",
    "BDT_LOOSE_CUTS += ' and tksh_distance<12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-determined boosting round numbers\n",
    "lc_rounds = 200\n",
    "\n",
    "# test train split \n",
    "split = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT training \n",
    "bdt_lc = main_BDT(datasets, BDT_LOOSE_CUTS, lc_rounds, test_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = bdt_lc[0]\n",
    "bdt_model = bdt_lc[1]\n",
    "train_df = bdt_lc[2]\n",
    "test_df = bdt_lc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we want to save \n",
    "# bdt_model.save_model(\"bdt_model_feb2021.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split events into different categories \n",
    "datasets_bdt = split_events(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mc --> BDT score\n",
    "plot_mc('BDT_score', 20, 0, 1, '', datasets_bdt, ISRUN3, plt_norm='proj', \n",
    "        pot='9.23E20', ymax=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot neutrino energy with systematics \n",
    "plot_mc('nu_e', [x/4 for x in range(21)], 0, 5, 'BDT_score>0.575', datasets_bdt, ISRUN3, \n",
    "        plt_norm='proj', pot='9.23E20', ymax=140, sys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of the linear selection for comparison \n",
    "\n",
    "gen_num = sum(test_df.query('is_signal==1 or is_cont_signal==1')['totweight_overlay'])\n",
    "eff_box = sum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay'])/gen_num * 100\n",
    "\n",
    "tot_sel = np.nansum(test_df.query(SEL_QUERY)['weight']) # EXT does not have totweight_overlay \n",
    "pur_box = sum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay']) / tot_sel * 100\n",
    "\n",
    "results_box = [pur_box, eff_box]\n",
    "\n",
    "# with stat errors on the linear performance \n",
    "e = eff_box/100\n",
    "\n",
    "eff_err = math.sqrt( (e*(1-e)) / gen_num ) * 100\n",
    "pur_err = math.sqrt(sum(test_df.query(SEL_QUERY+' and is_signal==1')['totweight_overlay'])) / tot_sel * 100\n",
    "\n",
    "results_box_err = [pur_err, eff_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values\n",
    "x = np.arange(0, 0.8, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns purity, purErr, eff, effErr\n",
    "perf = bdt_pe(results_df, x, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_box_plot(perf, results_box, x, ISRUN3, save=False, results_box_err=results_box_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW, apply the model to real data for data/MC comparisons\n",
    "\n",
    "varlist = [\n",
    "    \"shr_score\", \"shrmoliereavg\", \"trkpid\",\n",
    "    \"n_showers_contained\", \"shr_tkfit_dedx_Y\", \"tksh_distance\",\n",
    "    \"tksh_angle\", \"subcluster\", \"trkshrhitdist2\"]\n",
    "\n",
    "# apply cuts\n",
    "data_bdt = data.copy()\n",
    "data_bdt = data_bdt.query(BDT_LOOSE_CUTS)\n",
    "\n",
    "# clean datasets \n",
    "for column in varlist:\n",
    "        data_bdt.loc[(data_bdt[column] < -1.0e37) | (data_bdt[column] > 1.0e37), column] = np.nan\n",
    "    \n",
    "# create testing dmatrix \n",
    "data_test = xgb.DMatrix(data=data_bdt[varlist])\n",
    "    \n",
    "# apply the bdt selection\n",
    "preds = bdt_model.predict(data_test)\n",
    "\n",
    "# add columns for plotting \n",
    "data_bdt['BDT_score'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bdt.append(data_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('BDT_score', [x/10 for x in range(11)], 0, 1, '', datasets_bdt, ISRUN3, \n",
    "          plt_norm='pot', ymax=150, x_label='BDT Score') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT data/MC Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after SW trigger & nslice cuts\n",
    "\n",
    "q = 'nslice==1'\n",
    "\n",
    "plot_data('reco_nu_vtx_sce_x', 30, 0, 250, q,  datasets, ISRUN3, #ymax=25000,\n",
    "          x_label=\"Reconstructed Interaction Vertex (X) [cm]\", save=True, save_label='fhc_data')\n",
    "plot_data('reco_nu_vtx_sce_y', 30, 0, 120, q,  datasets, ISRUN3, #ymax=20000,\n",
    "          x_label=\"Reconstructed Interaction Vertex (Y) [cm]\")\n",
    "plot_data('reco_nu_vtx_sce_z', 30, 0, 1040, q,  datasets, ISRUN3, #ymax=17500,\n",
    "          x_label=\"Reconstructed Interaction Vertex (z) [cm]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after SW trigger, slice ID, and FV (quality cuts)\n",
    "\n",
    "# after nslice & containment cuts\n",
    "q += ' and '+reco_in_fv_query+ ' and contained_fraction>0.9'\n",
    "\n",
    "plot_data('n_showers_contained', 5, 0, 5, q, datasets, ISRUN3, x_label=\"Number of Showers\", ymax=15000)\n",
    "plot_data('n_tracks_contained', 7, 0, 7, q, datasets, ISRUN3, x_label='Number of Tracks', ymax=13000)\n",
    "plot_data('shr_energy_tot_cali', 10, 0, 0.25, q, datasets, ISRUN3, x_label='Total Calibrated Shower Energy [GeV]', ymax=16000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT preselection \n",
    "\n",
    "#shower score \n",
    "#trk PID\n",
    "#shrmoliereavg \n",
    "#shr_tkfit_dedx_Y\n",
    "#tksh_distance\n",
    "\n",
    "q = BDT_PRE_QUERY\n",
    "\n",
    "plot_data('shr_score', 10, 0, .5, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score', ymax=1200) \n",
    "plot_data('trkpid', 10, -1, 1, q, datasets, ISRUN3, x_label='Track PID Score', ymax=800) \n",
    "\n",
    "plot_data('shrmoliereavg', 8, 0, 40, q, datasets, ISRUN3, x_label='Avg Shower Moliere Angle [degrees]', \n",
    "          ymax=700)\n",
    "\n",
    "plot_data('shr_tkfit_dedx_Y', 10, 0, 10, q, datasets, ISRUN3, \n",
    "          x_label='dE/dx on the Collection Plane [MeV/cm]', ymax=500) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT Loose cuts\n",
    "\n",
    "#shr_score\n",
    "#shrmoliereavg \n",
    "#trk pid\n",
    "#n_showers_contained\n",
    "#subcluster\n",
    "#trkshrhitdist2\n",
    "\n",
    "q = BDT_LOOSE_CUTS\n",
    "\n",
    "\n",
    "plot_data('shr_score', 10, 0, .3, q, datasets, ISRUN3, x_label='Pandora Leading Shower Score', ymax=300) \n",
    "\n",
    "plot_data('shrmoliereavg', 5, 0, 15, q, datasets, ISRUN3, x_label='Avg Shower Moliere Angle [degrees]', \n",
    "        ymax=175)\n",
    "\n",
    "plot_data('trkpid', 10, -1, .35, q, datasets, ISRUN3, x_label='Track PID Score', ymax=130) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after BDT selection - now switch to datasets_BDT dataframes \n",
    "\n",
    "plot_data('BDT_score', 11, 0, 1, '', datasets_bdt, ISRUN3, plt_norm='pot', ymax=120, \n",
    "         save=False, save_label='fhc_data_BDT', sys=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
