{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slim dataframes for upstream data/mc comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'backend_functions')\n",
    "\n",
    "import importlib\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import top \n",
    "importlib.reload(top)\n",
    "from top import *\n",
    "\n",
    "\n",
    "\n",
    "import selection_functions as sf\n",
    "importlib.reload(sf)\n",
    "from selection_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3??\n",
    "ISRUN3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NuMIGeoWeights\n",
    "importlib.reload(NuMIGeoWeights)\n",
    "\n",
    "if ISRUN3: \n",
    "    current = \"RHC\"\n",
    "    \n",
    "else: \n",
    "    current = \"FHC\"\n",
    "\n",
    "numiBeamlineGeoWeights = NuMIGeoWeights.NuMIGeoWeights(current=current) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nue intrinsic? \n",
    "NUE_INTRINSIC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_path = parameters(ISRUN3)['plots_path']\n",
    "plots_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "DATA = \"\"\n",
    "EXT = \"\"\n",
    "OVRLY  = \"\"\n",
    "DRT = \"\"\n",
    "NUE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISRUN3: \n",
    "    path = \"/uboone/data/users/kmiller/uBNuMI_CCNp/ntuples/run3b/cv/\"\n",
    "    print('path = ', path)\n",
    "    \n",
    "        \n",
    "    # Run 3 RHC\n",
    "    OVRLY = 'neutrinoselection_filt_run3b_overlay_v7'\n",
    "    DATA = 'neutrinoselection_filt_run3b_beamon_beamgood_v5'\n",
    "    EXT = 'neutrinoselection_filt_run3b_beamoff_v5'\n",
    "    DRT = 'neutrinoselection_filt_run3b_dirt_overlay_v6'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'neutrinoselection_filt_run3b_overlay_intrinsic_v7'\n",
    "    \n",
    "else: \n",
    "    \n",
    "    path = \"/uboone/data/users/kmiller/uBNuMI_CCNp/ntuples/run1/cv/\"\n",
    "    print('path = ', path)\n",
    "    \n",
    "    # Run 1 FHC \n",
    "    OVRLY = 'neutrinoselection_filt_run1_overlay_v7'\n",
    "    EXT = 'neutrinoselection_filt_run1_beamoff_v5'\n",
    "    DATA = 'neutrinoselection_filt_run1_beamon_beamgood_v5'\n",
    "    DRT = 'prodgenie_numi_uboone_overlay_dirt_fhc_mcc9_run1_v28_all_snapshot'\n",
    "    \n",
    "    if NUE_INTRINSIC: \n",
    "        NUE = 'neutrinoselection_filt_run1_overlay_intrinsic_v7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = uproot.open(path+OVRLY+\".root\")[fold][tree]\n",
    "data = uproot.open(path+DATA+\".root\")[fold][tree]\n",
    "ext = uproot.open(path+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(path+DRT+\".root\")[fold][tree]  \n",
    "\n",
    "uproot_v = [overlay,data,ext,dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue = uproot.open(path+NUE+\".root\")[fold][tree]\n",
    "    uproot_v.append(nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nslice\", \n",
    "    \"contained_fraction\", \"run\"\n",
    "]\n",
    "\n",
    "# MC only variables\n",
    "mc_var = [\"nu_pdg\", \"ccnc\", \n",
    "          \"nproton\",  \"npi0\", \"npion\",\n",
    "          \"true_nu_vtx_x\", \"true_nu_vtx_y\" , \"true_nu_vtx_z\", \n",
    "          \"weightSplineTimesTune\", \"weightTune\",\n",
    "          \"swtrig_pre\", \"ppfx_cv\", 'nu_e', \"true_nu_px\", \"true_nu_py\", \"true_nu_pz\"]\n",
    "\n",
    "sys_genie_unisim = [\n",
    "             \"knobRPAup\", \"knobRPAdn\", \n",
    "             \"knobCCMECup\", \n",
    "             \"knobAxFFCCQEup\", \n",
    "             \"knobVecFFCCQEup\", \n",
    "             \"knobDecayAngMECup\", \n",
    "             \"knobThetaDelta2Npiup\", \n",
    "             \"knobThetaDelta2NRadup\", \n",
    "             \"knobNormCCCOHup\", \n",
    "             \"knobNormNCCOHup\",   \n",
    "             \"knobxsr_scc_Fv3up\",  # these are supposed to be multisims - 10 universes each -- map to pull out\n",
    "             \"knobxsr_scc_Fa3up\" ]\n",
    "\n",
    "sys_flux = ['weightsPPFX']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create slim pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start:\",datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "overlay = overlay.pandas.df(variables+mc_var+sys_genie_unisim, flatten=False)\n",
    "\n",
    "print(\"end:\",datetime.now().strftime(\"%H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt = dirt.pandas.df(variables+mc_var+sys_genie_unisim[:-2], flatten=False)\n",
    "dirt = dirt.query('swtrig_pre==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt['knobxsr_scc_Fv3up'] = 1\n",
    "dirt['knobxsr_scc_Fa3up'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUE_INTRINSIC: \n",
    "    nue = nue.pandas.df(variables+mc_var+sys_genie_unisim, flatten=False)\n",
    "    nue = nue.query('swtrig_pre==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.pandas.df(variables, flatten=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ext.pandas.df(variables, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in mc_var: \n",
    "    data[var] = np.nan\n",
    "    ext[var] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay['isDirt'] = False\n",
    "dirt['isDirt'] = True\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['isDirt'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['isDirt'] = np.nan\n",
    "ext['isDirt'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = [overlay, dirt]\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    mc_df.append(nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    # is signal bool \n",
    "    df['is_signal'] = np.where((df.swtrig_pre == 1) \n",
    "                             & (df.nu_pdg==12) & (df.ccnc==0) & (df.nproton>0) & (df.npion==0) & (df.npi0==0)\n",
    "                             & (10 <= df.true_nu_vtx_x) & (df.true_nu_vtx_x <= 246)\n",
    "                             & (-106 <= df.true_nu_vtx_y) & (df.true_nu_vtx_y <= 106)\n",
    "                             & (10 <= df.true_nu_vtx_z) & (df.true_nu_vtx_z <= 1026), True, False)\n",
    "    \n",
    "    # add beamline geometry weights\n",
    "    df = addAngles(df)\n",
    "    df['weightsNuMIGeo'] = df.apply( lambda x: numiBeamlineGeoWeights.calculateGeoWeight(x['nu_pdg'],x['nu_e'],x['thbeam']) , axis=1)\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nue.query('is_signal==True'))==len(nue.query(signal)))\n",
    "print(len(nue.query('is_signal==False'))==len(nue.query(not_signal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    # bad weights \n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 60, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    \n",
    "    # bad weights \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 60, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    for ievt in range(df.shape[0]): \n",
    "    \n",
    "\n",
    "        # check for NaNs separately        \n",
    "        if np.isnan(df['weightsPPFX'].iloc[ievt]).any() == True: \n",
    "            df['weightsPPFX'].iloc[ievt][ np.isnan(df['weightsPPFX'].iloc[ievt]) ] = 1.\n",
    "        \n",
    "        reweightCondition2 = ((df['weightsPPFX'].iloc[ievt] > 600) | (df['weightsPPFX'].iloc[ievt] < 0)   |\n",
    "                             (df['weightsPPFX'].iloc[ievt] == np.inf))\n",
    "        df['weightsPPFX'].iloc[ievt][ reweightCondition2 ] = 1000.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsPPFX'].iloc[ievt]): \n",
    "            df['weightsPPFX'].iloc[ievt] = [1000 for k in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    universes = []\n",
    "\n",
    "    for evt in df[sys_genie_unisim].values: \n",
    "        universes.append( evt )\n",
    "            \n",
    "    # CLEAN GENIE UNISIM WEIGHTS & CREATE WEIGHTSGENIEUNISIM LIST \n",
    "    for v in sys_genie_unisim: \n",
    "        df.loc[ df[v] <= 0, v ] = 1.\n",
    "        df.loc[ df[v] == np.inf, v ] = 1.\n",
    "        df.loc[ df[v] > 60, v ] = 1.\n",
    "        df.loc[ np.isnan(df[v]) == True, v ] = 1.\n",
    "        \n",
    "    df['weightsGenieUnisim'] = universes\n",
    "    \n",
    "    for ievt in range(df.shape[0]):      \n",
    "        if np.isnan(df['weightsGenieUnisim'].iloc[ievt]).any() == True: \n",
    "            df['weightsGenieUnisim'].iloc[ievt][ np.isnan(df['weightsGenieUnisim'].iloc[ievt]) ] = 1.\n",
    "\n",
    "        reweightCondition = ((df['weightsGenieUnisim'].iloc[ievt] > 60) | (df['weightsGenieUnisim'].iloc[ievt] < 0)  | \n",
    "                                 (df['weightsGenieUnisim'].iloc[ievt] == np.inf) | (df['weightsGenieUnisim'].iloc[ievt] == np.nan))\n",
    "        df['weightsGenieUnisim'].iloc[ievt][ reweightCondition ] = 1.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    for ievt in range(df.shape[0]): \n",
    "    \n",
    "        # RE-INTERACTION WEIGHTS\n",
    "        \n",
    "        # check for NaNs separately        \n",
    "        if np.isnan(df['weightsReint'].iloc[ievt]).any() == True: \n",
    "            df['weightsReint'].iloc[ievt][ np.isnan(df['weightsReint'].iloc[ievt]) ] = 1.\n",
    "        \n",
    "        reweightCondition2 = ((df['weightsReint'].iloc[ievt] > 600) | (df['weightsReint'].iloc[ievt] < 0)   |\n",
    "                             (df['weightsReint'].iloc[ievt] == np.inf))\n",
    "        df['weightsReint'].iloc[ievt][ reweightCondition2 ] = 1000.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsReint'].iloc[ievt]): \n",
    "            df['weightsReint'].iloc[ievt] = [1000 for k in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(mc_df):\n",
    "    \n",
    "    for ievt in range(df.shape[0]): \n",
    "        \n",
    "        # check for NaNs separately        \n",
    "        if np.isnan(df['weightsGenie'].iloc[ievt]).any() == True: \n",
    "            df['weightsGenie'].iloc[ievt][ np.isnan(df['weightsGenie'].iloc[ievt]) ] = 1.\n",
    "        \n",
    "        reweightCondition2 = ((df['weightsGenie'].iloc[ievt] > 600) | (df['weightsGenie'].iloc[ievt] < 0)   |\n",
    "                             (df['weightsGenie'].iloc[ievt] == np.inf))\n",
    "        df['weightsGenie'].iloc[ievt][ reweightCondition2 ] = 1000.\n",
    "        \n",
    "        # if no variations exist for the event\n",
    "        if not list(df['weightsGenie'].iloc[ievt]): \n",
    "            df['weightsGenie'].iloc[ievt] = [1000 for k in range(600)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = overlay.query('swtrig_pre==1')\n",
    "dirt = dirt.query('swtrig_pre==1')\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    \n",
    "    \n",
    "    nue = nue.query('swtrig_pre==1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POT Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = pot_scale(ext, 'ext', ISRUN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pot_scale'] = [1 for x in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamon_pot = parameters(ISRUN3)['beamon_pot'] \n",
    "\n",
    "overlay = pot_scale(overlay, 'overlay', ISRUN3)\n",
    "dirt = pot_scale(dirt, 'dirt', ISRUN3)\n",
    "\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue = pot_scale(nue, 'intrinsic', ISRUN3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totweight_data scales to BEAMON\n",
    "\n",
    "overlay['totweight_data'] = overlay['pot_scale']*overlay['ppfx_cv']*overlay['weightSplineTimesTune']\n",
    "dirt['totweight_data'] = dirt['pot_scale']*dirt['ppfx_cv']*dirt['weightSplineTimesTune']\n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    nue['totweight_data'] = nue['pot_scale']*nue['ppfx_cv']*nue['weightSplineTimesTune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['totweight_data'] = np.nan\n",
    "ext['totweight_data'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nueCC events \n",
    "\n",
    "if NUE_INTRINSIC: \n",
    "    \n",
    "    print(\"# of nueCC in AV in overlay sample = \"+str(len(overlay.query(nueCC_query))))\n",
    "    len1 = len(overlay)\n",
    "    \n",
    "    idx = overlay.query(nueCC_query).index\n",
    "    overlay.drop(idx, inplace=True)\n",
    "    len2 = len(overlay) \n",
    "    print(\"# of nueCC in AV dropped in overlay = \"+str(len1-len2))\n",
    "    \n",
    "    overlay = pd.concat([overlay,nue], ignore_index=True)\n",
    "\n",
    "    # from here on out everything else should be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SW trigger, combine overlay + dirt as MC \n",
    "mc = pd.concat([overlay.query('swtrig_pre==1'),dirt.query('swtrig_pre==1')], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infv = mc.query(in_fv_query)\n",
    "outfv = mc.query(out_fv_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that everything is accounted for \n",
    "print(len(mc)==len(infv)+len(outfv))\n",
    "\n",
    "if not (len(mc)==len(infv)+len(outfv)):\n",
    "    d = len(mc) - (len(infv)+len(outfv))\n",
    "    print(d)\n",
    "    \n",
    "     \n",
    "    m = pd.concat([infv, outfv]) \n",
    "    diff = np.setdiff1d(list(mc.index),list(m.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_signal_weighted = np.nansum(mc.query('is_signal==True')['totweight_data'])\n",
    "print('total signal events in FV = '+ str(tot_signal_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"infv\": infv, \n",
    "    \"outfv\": outfv,\n",
    "    \"ext\": ext,\n",
    "    \"data\": data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flash time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 0.359 us shift between beam on & beam off hardware trigger \n",
    "\n",
    "overlay['flash_time'] = overlay['flash_time']  - 0.359\n",
    "dirt['flash_time'] = dirt['flash_time']  - 0.359\n",
    "ext['flash_time'] = ext['flash_time'] - 0.359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_data, b_data, p_data = plt.hist(data['flash_time'], 50, range=[0, 25])\n",
    "data_bins = 0.5*(b_data[1:]+b_data[:-1])\n",
    "plt.close()\n",
    "\n",
    "x_err = [ (b_data[i+1]-b_data[i])/2 for i in range(len(b_data)-1) ]\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[2, 1])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "    \n",
    "ax1.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "ax2.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "\n",
    "n = ax1.hist([ext['flash_time'], \n",
    "              overlay['flash_time'], \n",
    "              dirt['flash_time']], 50, range=[0, 25], stacked=True, \n",
    "            weights=[ ext['pot_scale']*0.98, \n",
    "                 overlay['ppfx_cv']*overlay['weightSplineTimesTune']*overlay['pot_scale'], \n",
    "                 dirt['ppfx_cv']*dirt['weightSplineTimesTune']*dirt['pot_scale']*0.45], \n",
    "         color=['linen', 'limegreen', 'peru'], \n",
    "         label=['EXT', 'In Cryo MC', 'Dirt'])[0]\n",
    "\n",
    "ax1.errorbar(data_bins, n_data, yerr=np.sqrt(n_data), xerr=x_err, \n",
    "             color=\"black\", fmt='o', markersize=3, label='DATA')\n",
    "\n",
    "\n",
    "ax1.legend(fontsize=12)\n",
    "\n",
    "#ax2.yaxis.grid(linestyle=\"--\", color='black', alpha=0.7)\n",
    "ax2.axhline(1, color='black', lw=1, linestyle='--')\n",
    "ax2.set_ylim(0.8, 1.2)\n",
    "\n",
    "ax2.errorbar(data_bins, n_data/n[-1], \n",
    "             yerr=get_ratio_err(n_data, n[-1]), xerr=x_err, \n",
    "             color=\"black\", fmt='.')\n",
    "\n",
    "\n",
    "ax1.set_ylabel('Events / 5$\\\\times10^{20}$ POT', fontsize=15)\n",
    "\n",
    "ax2.set_xlabel('Flash Time [$\\\\mu$s]', fontsize=15)\n",
    "\n",
    "ax1.set_xlim(0, 25)\n",
    "ax2.set_xlim(0, 25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "ax1.set_title(\"\", fontsize=15)\n",
    "ax1.set_title(\"RHC Run 3: Flash Time (98% EXT Tune and 45% Dirt Tune)\", fontsize=15)\n",
    "plt.savefig(parameters(ISRUN3)['plots_path']+\"RHCRUN3_flashtime_full_tune.pdf\", transparent=True, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_data, b_data, p_data = plt.hist(data['flash_time'], 9, range=[1, 5.5])\n",
    "data_bins = 0.5*(b_data[1:]+b_data[:-1])\n",
    "plt.close()\n",
    "\n",
    "x_err = [ (b_data[i+1]-b_data[i])/2 for i in range(len(b_data)-1) ]\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[2, 1])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "    \n",
    "ax1.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "ax2.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "\n",
    "n = ax1.hist([ext['flash_time'], \n",
    "              overlay['flash_time'], \n",
    "              dirt['flash_time']], 9, range=[1, 5.5], stacked=True, \n",
    "            weights=[ ext['pot_scale']*0.98, \n",
    "                 overlay['ppfx_cv']*overlay['weightSplineTimesTune']*overlay['pot_scale'], \n",
    "                 dirt['ppfx_cv']*dirt['weightSplineTimesTune']*dirt['pot_scale']*0.45], \n",
    "         color=['linen', 'limegreen', 'peru'], \n",
    "         label=['EXT', 'In Cryo MC', 'Dirt'])[0]\n",
    "\n",
    "\n",
    "\n",
    "ax1.errorbar(data_bins, n_data, yerr=np.sqrt(n_data), xerr=x_err, \n",
    "             color=\"black\", fmt='o', markersize=3, label='DATA')\n",
    "\n",
    "ax1.legend(fontsize=13)\n",
    "\n",
    "#ax2.yaxis.grid(linestyle=\"--\", color='black', alpha=0.7)\n",
    "ax2.axhline(1.0, color='black', lw=1, linestyle='--')\n",
    "#ax2.axhline(np.average(n_data/n[-1]), color='black', lw=1, linestyle='--', \n",
    "#            label='Average = '+str( round(np.average((n_data/n[-1])), 3) ))\n",
    "ax2.set_ylim(0.8, 1.2)\n",
    "\n",
    "ax2.errorbar(data_bins, n_data/n[-1], \n",
    "             yerr=get_ratio_err(n_data, n[-1]), xerr=x_err, \n",
    "             color=\"black\", fmt='.', label='Average = '+str( round(np.average((n_data/n[-1])), 2)))\n",
    "\n",
    "ax2.legend(fontsize=13)\n",
    "\n",
    "ax1.set_ylabel('Events / 5$\\\\times10^{20}$ POT', fontsize=15)\n",
    "\n",
    "ax2.set_xlabel('Flash Time [$\\\\mu$s]', fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlim(1, 5.5)\n",
    "ax2.set_xlim(1, 5.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "ax1.set_title(\"RHC Run 3: Flash Time (98% EXT Tune and 45% Dirt Tune)\", fontsize=15)\n",
    "plt.savefig(parameters(ISRUN3)['plots_path']+\"RHCRUN3_flashtime_ext_tune.pdf\", transparent=True, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_data, b_data, p_data = plt.hist(data['flash_time'], 1, range=[5.64, 15.44])\n",
    "data_bins = 0.5*(b_data[1:]+b_data[:-1])\n",
    "plt.close()\n",
    "\n",
    "x_err = [ (b_data[i+1]-b_data[i])/2 for i in range(len(b_data)-1) ]\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[2, 1])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "    \n",
    "ax1.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "ax2.tick_params(axis = 'both', which = 'major', labelsize = 14)\n",
    "\n",
    "n = ax1.hist([ext['flash_time'], overlay['flash_time'], dirt['flash_time']], 1, range=[5.64, 15.44], stacked=True, \n",
    "            weights=[ ext['pot_scale']*0.98, \n",
    "                 overlay['ppfx_cv']*overlay['weightSplineTimesTune']*overlay['pot_scale'], \n",
    "                 dirt['ppfx_cv']*dirt['weightSplineTimesTune']*dirt['pot_scale']*0.45], \n",
    "         color=['linen', 'limegreen', 'peru'], \n",
    "         label=['EXT', 'In Cryo MC', 'Dirt'])[0]\n",
    "\n",
    "\n",
    "ax1.errorbar(data_bins, n_data, yerr=np.sqrt(n_data), xerr=x_err, \n",
    "             color=\"black\", fmt='o', markersize=3, label='DATA')\n",
    "\n",
    "ax1.legend(fontsize=13)\n",
    "\n",
    "#ax2.yaxis.grid(linestyle=\"--\", color='black', alpha=0.7)\n",
    "ax2.axhline(1.0, color='black', lw=1, linestyle='--')\n",
    "ax2.set_ylim(0.8, 1.2)\n",
    "\n",
    "ax2.errorbar(data_bins, n_data/n[-1], \n",
    "             yerr=get_ratio_err(n_data, n[-1]), xerr=x_err, \n",
    "             color=\"black\", fmt='.', label='Average = '+str(round((n_data/n[-1])[0], 2)))\n",
    "\n",
    "ax1.set_ylabel('Events / 5$\\\\times10^{20}$ POT', fontsize=15)\n",
    "ax2.set_xlabel('Flash Time [$\\\\mu$s]', fontsize=15)\n",
    "\n",
    "\n",
    "ax2.legend(fontsize=13)\n",
    "ax1.set_xlim(5.64, 15.44)\n",
    "ax2.set_xlim(5.64, 15.44)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "ax1.set_title(\"RHC RUN 3: Flash Time (98% EXT Tune and 45% Dirt Tune)\", fontsize=15)\n",
    "#plt.savefig(parameters(ISRUN3)['plots_path']+\"RHCRUN3_window_tune.pdf\", transparent=True, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ISRUN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Selection Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xvar = 'nslice'\n",
    "#bins = [-0.5, 0.5, 1.5]\n",
    "#x_label = \"Pandora Slice ID\"\n",
    "\n",
    "#xvar = \"reco_nu_vtx_sce_x\"\n",
    "#bins = [x*10 for x in range(27)]\n",
    "#x_label = 'Reconstructed Interaction Vertex (X) [cm]'\n",
    "\n",
    "#xvar = \"reco_nu_vtx_sce_y\"\n",
    "#bins = [-120, -110, -100, -90, -80, -70, -60, -50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "#x_label = 'Reconstructed Interaction Vertex (Y) [cm]'\n",
    "\n",
    "#xvar = 'reco_nu_vtx_sce_z'\n",
    "#bins = [x*40 for x in range(27)]\n",
    "#x_label = 'Reconstructed Interaction Vertex (Z) [cm]'\n",
    "\n",
    "xvar = 'contained_fraction'\n",
    "bins = [0, .10, .20, .30, .40, .50, .60, .70, .80, .90, 1]\n",
    "x_label = \"Contained Fraction\"\n",
    "\n",
    "true_var = ''\n",
    "beamon_pot = \"$5.0\\\\times10^{20}$\"\n",
    "xlow = bins[0]\n",
    "xhigh = bins[-1]\n",
    "\n",
    "q = BDT_PRE_QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total signal events in FV = 865.5972243538858')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_total = plot_mc(xvar, bins, xlow, xhigh, q, datasets, ISRUN3, norm='data')['CV']\n",
    "#ncv_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPFX, GENIE, GEANT4 multisims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uncertainty_functions \n",
    "importlib.reload(uncertainty_functions)\n",
    "from uncertainty_functions import *#plotSysVariations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncv, geant4_variations = plotSysVariations(true_var, xvar, bins, xlow, xhigh, '', datasets, 'weightsReint', 1000, \n",
    "#                                         ISRUN3, plot=False, background_subtraction=False)\n",
    "\n",
    "print(\"start:\",datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "#ncv, ppfx_variations = plotSysVariations(xvar, bins, xlow, xhigh, q, datasets, \n",
    "#                                           'weightsPPFX', 600, ISRUN3, plot=True)\n",
    "\n",
    "#ncv, genie_variations = plotSysVariations(xvar, bins, xlow, xhigh, q, datasets, 'weightsGenie', 600, \n",
    "#                                         ISRUN3, plot=True, background_subtraction=False)\n",
    "\n",
    "ncv, geant4_variations = plotSysVariations(xvar, bins, xlow, xhigh, q, datasets, 'weightsReint', 1000, \n",
    "                                         ISRUN3, plot=True, background_subtraction=False)\n",
    "\n",
    "print(\"end:\",datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = calcCov(xvar, bins, ncv, ncv_total, geant4_variations, plot=False, save=False,isrun3=ISRUN3)['fractional_uncertainty']\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENIE unisims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the tune weight out of everything except SCC variations\n",
    "# don't divide the tune weight out of SCC variations \n",
    "\n",
    "genie_unisim_variations = ['RPA', \n",
    "                           'CCMEC', 'AxFFCCQE', 'VecFFCCQE', 'DecayAngMEC', 'ThetaDelta2Npi', 'ThetaDelta2NRad', \n",
    "                          'NormCCCOH', 'NormNCCOH', \n",
    "                          'xsr_scc_Fv3', 'xsr_scc_Fa3']\n",
    "\n",
    "\n",
    "genie_unisim_cov = {}\n",
    "\n",
    "\n",
    "for knob in genie_unisim_variations: \n",
    "    \n",
    "    if knob == 'RPA': \n",
    "        idx = [sys_genie_unisim.index('knobRPAup'), sys_genie_unisim.index('knobRPAdn')]\n",
    "    \n",
    "    else: \n",
    "        idx = [sys_genie_unisim.index('knob'+knob+'up')]\n",
    "    \n",
    "    ncv_nu, variations = plotSysVariations(xvar, bins, xlow, xhigh, q, datasets, 'weightsGenieUnisim', \n",
    "                                        idx, ISRUN3, plot=True, axis_label='Reco '+x_label, \n",
    "                                        pot=str(beamon_pot)+\" POT\", \n",
    "                                        background_subtraction=False, title=knob)\n",
    "    \n",
    "    # calc covariance \n",
    "    genie_unisim_cov[knob] = calcCov(xvar, bins, ncv_nu, ncv_total, variations, save=False, \n",
    "                    axis_label='Reco '+x_label, pot=str(beamon_pot)+\" POT\", isrun3=ISRUN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute total covariance, correlation, & uncertainty \n",
    "\n",
    "cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "frac_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "cor = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "for variation in genie_unisim_cov.keys(): \n",
    "    \n",
    "    for i in range(len(bins)-1): \n",
    "        for j in range(len(bins)-1):\n",
    "            \n",
    "            cov[i][j] += genie_unisim_cov[variation]['cov'][i][j]\n",
    "            frac_cov[i][j] += genie_unisim_cov[variation]['frac_cov'][i][j] \n",
    "\n",
    "            \n",
    "for i in range(len(bins)-1): \n",
    "    for j in range(len(bins)-1):\n",
    "        \n",
    "        if np.sqrt(cov[i][i])*np.sqrt(cov[j][j]) != 0: \n",
    "                cor[i][j] = cov[i][j] / (np.sqrt(cov[i][i])*np.sqrt(cov[j][j]))\n",
    "        \n",
    "            \n",
    "genie_unisim_dict = {\n",
    "    'cov' : cov, \n",
    "    'frac_cov' : frac_cov,\n",
    "    'cor' : cor,\n",
    "    'fractional_uncertainty' : np.sqrt(np.diag(frac_cov))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_unisim_dict['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beamline geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered by beamline variation run number\n",
    "# [+1sigma run #, -1sigma run #]\n",
    "\n",
    "beamline_runs = {\n",
    "    'HornCurrent' : [1, 2], \n",
    "    'xHorn1' : [3, 4], \n",
    "    'yHorn1' : [5, 6], \n",
    "    'BeamSpotSize' : [7, 8], \n",
    "    'xHorn2' : [9, 10], \n",
    "    'yHorn2' : [11, 12], \n",
    "    'WaterOnHorns' : [13, 14], \n",
    "    'xBeamShift' : [15, 16], \n",
    "    'yBeamShift' : [17, 18], \n",
    "    'zTargetPosition' : [19, 20]    \n",
    "}\n",
    "\n",
    "beamline_cov = {}\n",
    "\n",
    "# index in weightsNuMIGeo are offset by -1\n",
    "\n",
    "for variation in beamline_runs.keys(): \n",
    "    \n",
    "    idx = [i-1 for i in beamline_runs[variation]]\n",
    "    print(idx)\n",
    "    \n",
    "    ncv_nu, beamline_variations = plotSysVariations(xvar, bins, xlow, xhigh, q, datasets, 'weightsNuMIGeo', \n",
    "                                                 idx, ISRUN3, plot=True, \n",
    "                                                 axis_label='Reco '+x_label, pot=str(beamon_pot)+\" POT\", \n",
    "                                                  background_subtraction=False)\n",
    "    \n",
    "    # calc covariance \n",
    "    beamline_cov[variation] = calcCov(xvar, bins, ncv_nu, ncv_total, \n",
    "                                      beamline_variations, save=False, isrun3=ISRUN3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute total covariance, correlation, & uncertainty \n",
    "\n",
    "cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "frac_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "cor = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "for variation in beamline_cov.keys(): \n",
    "    \n",
    "    for i in range(len(bins)-1): \n",
    "        for j in range(len(bins)-1):\n",
    "            \n",
    "            cov[i][j] += beamline_cov[variation]['cov'][i][j]\n",
    "            frac_cov[i][j] += beamline_cov[variation]['frac_cov'][i][j] \n",
    "\n",
    "            \n",
    "for i in range(len(bins)-1): \n",
    "    for j in range(len(bins)-1):\n",
    "        \n",
    "        if np.sqrt(cov[i][i])*np.sqrt(cov[j][j]) != 0: \n",
    "                cor[i][j] = cov[i][j] / (np.sqrt(cov[i][i])*np.sqrt(cov[j][j]))\n",
    "            \n",
    "beamline_dict = {\n",
    "    'cov' : cov, \n",
    "    'frac_cov' : frac_cov,\n",
    "    'cor' : cor,\n",
    "    'fractional_uncertainty' : np.sqrt(np.diag(frac_cov))\n",
    "} \n",
    "\n",
    "beamline_dict['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stat uncertainty, POT counting, dirt uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't include EXT uncertainty \n",
    "\n",
    "mc_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "mc_frac_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "\n",
    "ncv = pd.concat([datasets['infv'].copy().query(q), \n",
    "                         datasets['outfv'].copy().query(q)], ignore_index=True) \n",
    "\n",
    "    \n",
    "for i in range(len(bins)-1):\n",
    "\n",
    "    if i==len(bins)-2: \n",
    "        bin_query = xvar+' >= '+str(bins[i])+' and '+xvar+' <= '+str(bins[i+1])\n",
    "    else: \n",
    "        bin_query = xvar+' >= '+str(bins[i])+' and '+xvar+' < '+str(bins[i+1])\n",
    "        \n",
    "    mc_stat_cov[i][i] = sum(ncv.query(bin_query).totweight_data ** 2) \n",
    "    mc_frac_stat_cov[i][i] = mc_stat_cov[i][i]/ ncv_total[i]**2 \n",
    "    \n",
    "    bin_query = ''\n",
    "    \n",
    "mc_stat_percent_error = np.sqrt(np.diag(mc_frac_stat_cov))\n",
    "mc_stat_percent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAKE SURE TO UPDATE QUERY!\")\n",
    "\n",
    "# selected EXT uncertainty \n",
    "selected_ext = plt.hist(datasets['ext'].copy().query(q)[xvar], bins, \n",
    "                        weights=datasets['ext'].copy().query(q)['pot_scale'], color='gainsboro')[0]\n",
    "plt.show()\n",
    "#selected_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take fractional with respect to the full event rate\n",
    "\n",
    "ext_frac_stat_cov = [ [0]*(len(bins)-1) for x in range(len(bins)-1) ]\n",
    "\n",
    "for i in range(len(bins)-1): \n",
    "    \n",
    "    if selected_ext[i] != 0: \n",
    "        ext_frac_stat_cov[i][i] = selected_ext[i]/(ncv_total[i]**2)\n",
    "\n",
    "ext_stat_percent_error = np.sqrt(np.diag(ext_frac_stat_cov))\n",
    "ext_stat_percent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" make sure to update query !! \")\n",
    "\n",
    "\n",
    "selected_dirt = plt.hist(datasets['outfv'].copy().query('isDirt==1 and '+q)[xvar], \n",
    "                         bins, \n",
    "                        weights=datasets['outfv'].copy().query('isDirt==1 and '+q)['pot_scale'], \n",
    "                         color='orchid')[0]\n",
    "\n",
    "dirt_uncertainty = dirt_unisim(xvar, bins, ncv_total, selected_dirt, 1.0, ISRUN3, plot=True, \n",
    "                               x_label=None, title=None)\n",
    "\n",
    "dirt_uncertainty['fractional_uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_unc_dict = {\n",
    "    'ppfx' : [0.05003184, 0.05540721, 0.06575217, 0.07510058, 0.08219948,\n",
    "       0.08430634, 0.08376536, 0.08108476, 0.07446911, 0.06894182], \n",
    "    'beamline' : [0.01221571, 0.01474661, 0.01891112, 0.02240296, 0.02479625,\n",
    "       0.02669666, 0.02555649, 0.0249792 , 0.0208245 , 0.014175  ], \n",
    "    'genie_ms' : [0.10249865, 0.11068975, 0.12188674, 0.12902866, 0.14114819,\n",
    "       0.13491289, 0.13293626, 0.12761262, 0.11433713, 0.12111771] , \n",
    "    'genie_us' : [0.02405502, 0.0141924 , 0.01825566, 0.01446316, 0.02002141,\n",
    "       0.01838876, 0.01546312, 0.02245857, 0.01588048, 0.0211067 ],  \n",
    "    'geant4' : [0.00543066, 0.00836362, 0.01288351, 0.01729271, 0.02083988,\n",
    "       0.02399154, 0.02487714, 0.02431835, 0.02030531, 0.00899401], \n",
    "    'detector' : [0.122 for b in range(len(bins))], \n",
    "    'pot_counting' : [0.02 for b in range(len(bins))], \n",
    "    'dirt' : [0.04925296, 0.04136418, 0.04279413, 0.04140197, 0.03391021,\n",
    "       0.02899751, 0.03360654, 0.0351548 , 0.04255718, 0.04875334],\n",
    "    'mc_stat' : [0.00203453, 0.00451359, 0.00618092, 0.00731167, 0.00871424,\n",
    "       0.00910041, 0.00966499, 0.01011655, 0.00985783, 0.00232165],\n",
    "    'ext_stat' : [0.00365285, 0.00723994, 0.00846327, 0.0091422 , 0.00942974,\n",
    "       0.00985995, 0.0103545 , 0.01145858, 0.01315397, 0.00341109]\n",
    "}\n",
    "\n",
    "frac_unc_dict['total'] = [ a**2 + b**2 + c**2 + d**2 + e**2 + f**2 + g**2 + h**2 + i**2 + j**2 \n",
    "                                 for a,b,c,d,e,f,g,h,i,j in zip(frac_unc_dict['ppfx'], frac_unc_dict['beamline'], \n",
    "                                                               frac_unc_dict['genie_ms'], frac_unc_dict['genie_us'], \n",
    "                                                               frac_unc_dict['geant4'], frac_unc_dict['detector'], \n",
    "                                                               frac_unc_dict['pot_counting'], frac_unc_dict['dirt'], \n",
    "                                                               frac_unc_dict['mc_stat'], frac_unc_dict['ext_stat'])] \n",
    "\n",
    "frac_unc_dict['total'] = [np.sqrt(x) for x in frac_unc_dict['total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frac_unc_dict['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sf)\n",
    "from selection_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = plot_data(xvar, bins, xlow, xhigh, q, datasets, ISRUN3,\n",
    "                  save=False, save_label='nslice_infv_rhcrun3', log=False, x_label=x_label, \n",
    "                  y_label=beamon_pot, \n",
    "                 sys=frac_unc_dict['total'], \n",
    "                 text=\"RHC RUN 3\", xtext=0.75, ytext=16500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
